{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhIgGq3za0yh",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "# HW6 Diffusion Model\n",
    "\n",
    "**Sources:**\n",
    "- Github implementation [Denoising Diffusion Pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch)\n",
    "- Papers on Diffusion models ([Dhariwal, Nichol, 2021], [Ho et al., 2020] ect.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLHSIArLcFK0"
   },
   "source": [
    "## Import Packages and Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s1xegyILIuLz",
    "outputId": "b71ce929-c0bd-4ff0-ff53-cb01b421c2e9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: einops in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (0.8.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from transformers) (4.65.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: ema_pytorch in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: beartype in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from ema_pytorch) (0.18.5)\n",
      "Requirement already satisfied: torch>=1.6 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from ema_pytorch) (2.3.0)\n",
      "Requirement already satisfied: filelock in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.6->ema_pytorch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->ema_pytorch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from jinja2->torch>=1.6->ema_pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from sympy->torch>=1.6->ema_pytorch) (1.3.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: accelerate in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "!pip install transformers\n",
    "!pip install ema_pytorch\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LQnlc27k7Aiw",
    "outputId": "122e675a-a91b-4fa3-d56f-1f6bb38bc094"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from random import random\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T, utils\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from ema_pytorch import EMA\n",
    "\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Gradescope – Question 1\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(4096)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj17psVw7Shg"
   },
   "source": [
    "## Step 1: Forward process (Noise scheduler)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qWw50ui9IZ5q"
   },
   "outputs": [],
   "source": [
    "def linear_beta_schedule(timesteps):\n",
    "    \"\"\"\n",
    "    linear schedule, proposed in original ddpm paper\n",
    "    \"\"\"\n",
    "    scale = 1000 / timesteps\n",
    "    beta_start = scale * 0.0001\n",
    "    beta_end = scale * 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps, dtype = torch.float64)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008): # Strong\n",
    "    \"\"\"\n",
    "    cosine schedule as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos((x / timesteps + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def sigmoid_beta_schedule(timesteps, start = -3, end = 3, tau = 1, clamp_min = 1e-5):\n",
    "    \"\"\"\n",
    "    sigmoid schedule\n",
    "    proposed in https://arxiv.org/abs/2212.11972 - Figure 8\n",
    "    better for images > 64x64, when used during training\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    t = torch.linspace(0, timesteps, steps, dtype = torch.float64) / timesteps\n",
    "    v_start = torch.tensor(start / tau).sigmoid()\n",
    "    v_end = torch.tensor(end / tau).sigmoid()\n",
    "    alphas_cumprod = (-((t * (end - start) + start) / tau).sigmoid() + v_end) / (v_end - v_start)\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.999)\n",
    "    \n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vt6JSKawk7_b"
   },
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uuckjpW_k1LN"
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        folder,\n",
    "        image_size\n",
    "    ):\n",
    "        self.folder = folder\n",
    "        self.image_size = image_size\n",
    "        self.paths = [p for p in Path(f'{folder}').glob(f'**/*.jpg')]\n",
    "        #################################\n",
    "        ## DONE: Data Augmentation ##\n",
    "        #################################\n",
    "        \n",
    "        self.transform = T.Compose([ # Medium\n",
    "            T.Resize(image_size),\n",
    "            T.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "            T.RandomRotation(10),      # Random rotation\n",
    "            T.ColorJitter(brightness=0.25, contrast=0.25),  # Slight color adjustments\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path)\n",
    "        return self.transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buW6BaNga-XH"
   },
   "source": [
    "## Step 2: The backward process = U-Net\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYw6u0nJXIWy"
   },
   "source": [
    "Define some useful functions and U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DuJCCZ5dInQq"
   },
   "outputs": [],
   "source": [
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def identity(t, *args, **kwargs):\n",
    "    return t\n",
    "\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "\n",
    "def has_int_squareroot(num):\n",
    "    return (math.sqrt(num) ** 2) == num\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "# normalization functions\n",
    "\n",
    "def normalize_to_neg_one_to_one(img):\n",
    "    return img * 2 - 1\n",
    "\n",
    "def unnormalize_to_zero_to_one(t):\n",
    "    return (t + 1) * 0.5\n",
    "\n",
    "# small helper modules\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "def Upsample(dim, dim_out = None):\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
    "        nn.Conv2d(dim, default(dim_out, dim), 3, padding = 1)\n",
    "    )\n",
    "\n",
    "def Downsample(dim, dim_out = None):\n",
    "    return nn.Sequential(\n",
    "        Rearrange('b c (h p1) (w p2) -> b (c p1 p2) h w', p1 = 2, p2 = 2),\n",
    "        nn.Conv2d(dim * 4, default(dim_out, dim), 1)\n",
    "    )\n",
    "\n",
    "class WeightStandardizedConv2d(nn.Conv2d):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/1903.10520\n",
    "    weight standardization purportedly works synergistically with group normalization\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "\n",
    "        weight = self.weight\n",
    "        mean = reduce(weight, 'o ... -> o 1 1 1', 'mean')\n",
    "        var = reduce(weight, 'o ... -> o 1 1 1', partial(torch.var, unbiased = False))\n",
    "        normalized_weight = (weight - mean) * (var + eps).rsqrt()\n",
    "\n",
    "        return F.conv2d(x, normalized_weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
    "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
    "        return (x - mean) * (var + eps).rsqrt() * self.g\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "# sinusoidal positional embeds\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class RandomOrLearnedSinusoidalPosEmb(nn.Module):\n",
    "    \"\"\" following @crowsonkb 's lead with random (learned optional) sinusoidal pos emb \"\"\"\n",
    "    \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n",
    "\n",
    "    def __init__(self, dim, is_random = False):\n",
    "        super().__init__()\n",
    "        assert (dim % 2) == 0\n",
    "        half_dim = dim // 2\n",
    "        self.weights = nn.Parameter(torch.randn(half_dim), requires_grad = not is_random)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b -> b 1')\n",
    "        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n",
    "        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n",
    "        fouriered = torch.cat((x, fouriered), dim = -1)\n",
    "        return fouriered\n",
    "\n",
    "# building block modules\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.proj = WeightStandardizedConv2d(dim, dim_out, 3, padding = 1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift = None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim = None, groups = 8):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, dim_out * 2)\n",
    "        ) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups = groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups = groups)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb = None):\n",
    "\n",
    "        scale_shift = None\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, 'b c -> b c 1 1')\n",
    "            scale_shift = time_emb.chunk(2, dim = 1)\n",
    "\n",
    "        h = self.block1(x, scale_shift = scale_shift)\n",
    "\n",
    "        h = self.block2(h)\n",
    "\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, dim, 1),\n",
    "            LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
    "\n",
    "        q = q.softmax(dim = -2)\n",
    "        k = k.softmax(dim = -1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        v = v / (h * w)\n",
    "\n",
    "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.heads, x = h, y = w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = torch.einsum('b h d i, b h d j -> b h i j', q, k)\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        out = torch.einsum('b h i j, b h d j -> b h i d', attn, v)\n",
    "\n",
    "        out = rearrange(out, 'b h (x y) d -> b (h d) x y', x = h, y = w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "# model\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        init_dim = None,\n",
    "        out_dim = None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels = 3,\n",
    "        resnet_block_groups = 8,\n",
    "        learned_sinusoidal_cond = False,\n",
    "        random_fourier_features = False,\n",
    "        learned_sinusoidal_dim = 16\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "\n",
    "        self.channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim)\n",
    "        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding = 3)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "\n",
    "        time_dim = dim * 4\n",
    "\n",
    "        self.random_or_learned_sinusoidal_cond = learned_sinusoidal_cond or random_fourier_features\n",
    "\n",
    "        if self.random_or_learned_sinusoidal_cond:\n",
    "            sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n",
    "            fourier_dim = learned_sinusoidal_dim + 1\n",
    "        else:\n",
    "            sinu_pos_emb = SinusoidalPosEmb(dim)\n",
    "            fourier_dim = dim\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            sinu_pos_emb,\n",
    "            nn.Linear(fourier_dim, time_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "\n",
    "        # layers\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n",
    "            ]))\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
    "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                Upsample(dim_out, dim_in) if not is_last else  nn.Conv2d(dim_out, dim_in, 3, padding = 1)\n",
    "            ]))\n",
    "\n",
    "        self.out_dim = default(out_dim, channels)\n",
    "\n",
    "        self.final_res_block = block_klass(dim * 2, dim, time_emb_dim = time_dim)\n",
    "        self.final_conv = nn.Conv2d(dim, self.out_dim, 1)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "        r = x.clone()\n",
    "\n",
    "        t = self.time_mlp(time)\n",
    "\n",
    "        h = []\n",
    "\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            h.append(x)\n",
    "\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim = 1)\n",
    "            x = block1(x, t)\n",
    "\n",
    "            x = torch.cat((x, h.pop()), dim = 1)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = torch.cat((x, r), dim = 1)\n",
    "\n",
    "        x = self.final_res_block(x, t)\n",
    "        return self.final_conv(x)\n",
    "model = Unet(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B9GlZrotBXy"
   },
   "source": [
    "## Step 3: The Diffusion Process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph05t8MxXMoY"
   },
   "source": [
    "Define diffusion process, including generating noisy models, sample...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X7TKWoZpInQs"
   },
   "outputs": [],
   "source": [
    "class GaussianDiffusion(nn.Module): # Strong\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        *,\n",
    "        image_size,\n",
    "        timesteps = 1000,\n",
    "        beta_schedule = 'linear',\n",
    "        auto_normalize = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert not (type(self) == GaussianDiffusion and model.channels != model.out_dim)\n",
    "        assert not model.random_or_learned_sinusoidal_cond\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.channels = self.model.channels\n",
    "\n",
    "        self.image_size = image_size\n",
    "\n",
    "\n",
    "        if beta_schedule == 'linear':\n",
    "            beta_schedule_fn = linear_beta_schedule\n",
    "        elif beta_schedule == 'cosine':\n",
    "            beta_schedule_fn = cosine_beta_schedule\n",
    "        elif beta_schedule == 'sigmoid':\n",
    "            beta_schedule_fn = sigmoid_beta_schedule\n",
    "        else:\n",
    "            raise ValueError(f'unknown beta schedule {beta_schedule}')\n",
    "        \n",
    "        # calculate beta and other precalculated parameters\n",
    "        betas = beta_schedule_fn(timesteps)\n",
    "                                            \n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value = 1.)\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        # sampling related parameters\n",
    "\n",
    "        self.sampling_timesteps = timesteps # default num sampling timesteps to number of timesteps at training\n",
    "\n",
    "        # helper function to register buffer from float64 to float32\n",
    "\n",
    "        register_buffer = lambda name, val: self.register_buffer(name, val.to(torch.float32))\n",
    "\n",
    "        register_buffer('betas', betas)\n",
    "        register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "\n",
    "        register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "        register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n",
    "        register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n",
    "        register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "\n",
    "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "\n",
    "        register_buffer('posterior_variance', posterior_variance)\n",
    "\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "\n",
    "        register_buffer('posterior_log_variance_clipped', torch.log(posterior_variance.clamp(min =1e-20)))\n",
    "        register_buffer('posterior_mean_coef1', betas * torch.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n",
    "        register_buffer('posterior_mean_coef2', (1. - alphas_cumprod_prev) * torch.sqrt(alphas) / (1. - alphas_cumprod))\n",
    "\n",
    "        # derive loss weight\n",
    "        # snr - signal noise ratio\n",
    "\n",
    "        snr = alphas_cumprod / (1 - alphas_cumprod)\n",
    "\n",
    "        # https://arxiv.org/abs/2303.09556\n",
    "\n",
    "        maybe_clipped_snr = snr.clone()\n",
    "\n",
    "        register_buffer('loss_weight', maybe_clipped_snr / snr)\n",
    "\n",
    "        # auto-normalization of data [0, 1] -> [-1, 1] - can turn off by setting it to be False\n",
    "\n",
    "        self.normalize = normalize_to_neg_one_to_one if auto_normalize else identity\n",
    "        self.unnormalize = unnormalize_to_zero_to_one if auto_normalize else identity\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def predict_noise_from_start(self, x_t, t, x0):\n",
    "        return (\n",
    "            (extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - x0) / \\\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n",
    "        )\n",
    "\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
    "            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def model_predictions(self, x, t, clip_x_start = False, rederive_pred_noise = False):\n",
    "        model_output = self.model(x, t)\n",
    "        maybe_clip = partial(torch.clamp, min = -1., max = 1.) if clip_x_start else identity\n",
    "\n",
    "        pred_noise = model_output\n",
    "        x_start = self.predict_start_from_noise(x, t, pred_noise)\n",
    "        x_start = maybe_clip(x_start)\n",
    "\n",
    "        if clip_x_start and rederive_pred_noise:\n",
    "            pred_noise = self.predict_noise_from_start(x, t, x_start)\n",
    "\n",
    "        return pred_noise, x_start\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised = True):\n",
    "        noise, x_start = self.model_predictions(x, t)\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_start.clamp_(-1., 1.)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start = x_start, x_t = x, t = t)\n",
    "        return model_mean, posterior_variance, posterior_log_variance, x_start\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t: int):\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        batched_times = torch.full((b,), t, device = x.device, dtype = torch.long)\n",
    "        model_mean, _, model_log_variance, x_start = self.p_mean_variance(x = x, t = batched_times, clip_denoised = True)\n",
    "        noise = torch.randn_like(x) if t > 0 else 0. # no noise if t == 0\n",
    "        pred_img = model_mean + (0.5 * model_log_variance).exp() * noise\n",
    "        return pred_img, x_start\n",
    "\n",
    "    # Gradescope – Question 1\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, shape, return_all_timesteps = False, num_samples=5, save_path='./Q1_progressive_generation.png'):\n",
    "        batch, device = shape[0], self.betas.device\n",
    "\n",
    "        img = torch.randn(shape, device = device)\n",
    "        imgs = [img]\n",
    "        samples = [img[:num_samples]]  # Store initial noisy samples\n",
    "\n",
    "        x_start = None\n",
    "        \n",
    "        ###########################################\n",
    "        ## DONE: plot the sampling process ##\n",
    "        ###########################################\n",
    "        for t in tqdm(reversed(range(0, self.num_timesteps)), desc = 'sampling loop time step', total = self.num_timesteps):\n",
    "            img, x_start = self.p_sample(img, t)\n",
    "            imgs.append(img)\n",
    "            if t % (self.num_timesteps // 20) == 0:\n",
    "                samples.append(img[:num_samples])  # Store samples at specific steps\n",
    "        \n",
    "        ret = img if not return_all_timesteps else torch.stack(imgs, dim = 1)\n",
    "\n",
    "        ret = self.unnormalize(ret)\n",
    "        self.plot_progressive_generation(samples, len(samples)-1, save_path=save_path)\n",
    "        return ret\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size = 16, return_all_timesteps = False):\n",
    "        image_size, channels = self.image_size, self.channels\n",
    "        sample_fn = self.p_sample_loop\n",
    "        return sample_fn((batch_size, channels, image_size, image_size), return_all_timesteps = return_all_timesteps)\n",
    "\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def loss_fn(self):\n",
    "        return F.mse_loss\n",
    "\n",
    "\n",
    "    def p_losses(self, x_start, t, noise = None):\n",
    "        b, c, h, w = x_start.shape\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        # noise sample\n",
    "\n",
    "        x = self.q_sample(x_start = x_start, t = t, noise = noise)\n",
    "\n",
    "        # predict and take gradient step\n",
    "\n",
    "        model_out = self.model(x, t)\n",
    "\n",
    "        loss = self.loss_fn(model_out, noise, reduction = 'none')\n",
    "        loss = reduce(loss, 'b ... -> b (...)', 'mean')\n",
    "\n",
    "        loss = loss * extract(self.loss_weight, t, loss.shape)\n",
    "        return loss.mean()\n",
    "\n",
    "    def forward(self, img, *args, **kwargs):\n",
    "        b, c, h, w, device, img_size, = *img.shape, img.device, self.image_size\n",
    "        assert h == img_size and w == img_size, f'height and width of image must be {img_size}'\n",
    "        t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n",
    "\n",
    "        img = self.normalize(img)\n",
    "        return self.p_losses(img, t, *args, **kwargs)\n",
    "\n",
    "    # Gradescope – Question 1\n",
    "    def plot_progressive_generation(self, samples, num_steps, save_path=None):\n",
    "        fig, axes = plt.subplots(1, num_steps + 1, figsize=(20, 4))\n",
    "        for i, sample in enumerate(samples):\n",
    "            axes[i].imshow(vutils.make_grid(sample, nrow=1, normalize=True).permute(1, 2, 0).cpu().numpy())\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f'Step {i}')\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWJUjFIHInQt"
   },
   "source": [
    "Define Trainer: define the updating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ed12NNXPtDon"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        diffusion_model,\n",
    "        folder,\n",
    "        *,\n",
    "        train_batch_size = 16,\n",
    "        gradient_accumulate_every = 1,\n",
    "        train_lr = 1e-4,\n",
    "        train_num_steps = 100000,\n",
    "        ema_update_every = 10,\n",
    "        ema_decay = 0.995,\n",
    "        adam_betas = (0.9, 0.99),\n",
    "        save_and_sample_every = 1000,\n",
    "        num_samples = 25,\n",
    "        results_folder = './results',\n",
    "        split_batches = True,\n",
    "        inception_block_idx = 2048\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create DataLoaderConfiguration\n",
    "        dataloader_config = DataLoaderConfiguration(split_batches=split_batches)\n",
    "\n",
    "#         # accelerator\n",
    "\n",
    "#         self.accelerator = Accelerator(\n",
    "#             split_batches = split_batches,\n",
    "#             mixed_precision = 'no'\n",
    "#         )\n",
    "        \n",
    "        # Create Accelerator with DataLoaderConfiguration\n",
    "        self.accelerator = Accelerator(\n",
    "            dataloader_config=dataloader_config,\n",
    "            mixed_precision='no')\n",
    "        \n",
    "\n",
    "        # model\n",
    "\n",
    "        self.model = diffusion_model\n",
    "        self.channels = diffusion_model.channels\n",
    "\n",
    "        # sampling and training hyperparameters\n",
    "\n",
    "        assert has_int_squareroot(num_samples), 'number of samples must have an integer square root'\n",
    "        self.num_samples = num_samples\n",
    "        self.save_and_sample_every = save_and_sample_every\n",
    "\n",
    "        self.batch_size = train_batch_size\n",
    "        self.gradient_accumulate_every = gradient_accumulate_every\n",
    "\n",
    "        self.train_num_steps = train_num_steps\n",
    "        self.image_size = diffusion_model.image_size\n",
    "\n",
    "        # dataset and dataloader\n",
    "\n",
    "        self.ds = Dataset(folder, self.image_size)\n",
    "        dl = DataLoader(self.ds, batch_size = train_batch_size, shuffle = True, pin_memory = True, num_workers = cpu_count())\n",
    "\n",
    "        dl = self.accelerator.prepare(dl)\n",
    "        self.dl = cycle(dl)\n",
    "\n",
    "        # optimizer\n",
    "\n",
    "        self.opt = Adam(diffusion_model.parameters(), lr = train_lr, betas = adam_betas)\n",
    "\n",
    "        # for logging results in a folder periodically\n",
    "\n",
    "        if self.accelerator.is_main_process:\n",
    "            self.ema = EMA(diffusion_model, beta = ema_decay, update_every = ema_update_every)\n",
    "            self.ema.to(self.device)\n",
    "\n",
    "        self.results_folder = Path(results_folder)\n",
    "        self.results_folder.mkdir(exist_ok = True)\n",
    "\n",
    "        # step counter state\n",
    "\n",
    "        self.step = 0\n",
    "\n",
    "        # prepare model, dataloader, optimizer with accelerator\n",
    "\n",
    "        self.model, self.opt = self.accelerator.prepare(self.model, self.opt)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.accelerator.device\n",
    "\n",
    "    def save(self, milestone):\n",
    "        if not self.accelerator.is_local_main_process:\n",
    "            return\n",
    "\n",
    "        data = {\n",
    "            'step': self.step,\n",
    "            'model': self.accelerator.get_state_dict(self.model),\n",
    "            'opt': self.opt.state_dict(),\n",
    "            'ema': self.ema.state_dict(),\n",
    "            'scaler': self.accelerator.scaler.state_dict() if exists(self.accelerator.scaler) else None,\n",
    "        }\n",
    "\n",
    "        torch.save(data, str(self.results_folder / f'model-{milestone}.pt'))\n",
    "\n",
    "    def load(self, ckpt):\n",
    "        accelerator = self.accelerator\n",
    "        device = accelerator.device\n",
    "\n",
    "        data = torch.load(ckpt, map_location=device)\n",
    "\n",
    "        model = self.accelerator.unwrap_model(self.model)\n",
    "        model.load_state_dict(data['model'])\n",
    "\n",
    "        self.step = data['step']\n",
    "        self.opt.load_state_dict(data['opt'])\n",
    "        if self.accelerator.is_main_process:\n",
    "            self.ema.load_state_dict(data[\"ema\"])\n",
    "\n",
    "\n",
    "        if exists(self.accelerator.scaler) and exists(data['scaler']):\n",
    "            self.accelerator.scaler.load_state_dict(data['scaler'])\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        accelerator = self.accelerator\n",
    "        device = accelerator.device\n",
    "\n",
    "        with tqdm(initial = self.step, total = self.train_num_steps, disable = not accelerator.is_main_process) as pbar:\n",
    "\n",
    "            while self.step < self.train_num_steps:\n",
    "\n",
    "                total_loss = 0.\n",
    "\n",
    "                for _ in range(self.gradient_accumulate_every):\n",
    "                    data = next(self.dl).to(device)\n",
    "\n",
    "                    with self.accelerator.autocast():\n",
    "                        loss = self.model(data)\n",
    "                        loss = loss / self.gradient_accumulate_every\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "                    self.accelerator.backward(loss)\n",
    "\n",
    "                accelerator.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                pbar.set_description(f'loss: {total_loss:.4f}')\n",
    "\n",
    "                accelerator.wait_for_everyone()\n",
    "\n",
    "                self.opt.step()\n",
    "                self.opt.zero_grad()\n",
    "\n",
    "                accelerator.wait_for_everyone()\n",
    "\n",
    "                self.step += 1\n",
    "                if accelerator.is_main_process:\n",
    "                    self.ema.update()\n",
    "\n",
    "                    if self.step != 0 and self.step % self.save_and_sample_every == 0:\n",
    "                        self.ema.ema_model.eval()\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            milestone = self.step // self.save_and_sample_every\n",
    "                            batches = num_to_groups(self.num_samples, self.batch_size)\n",
    "                            all_images_list = list(map(lambda n: self.ema.ema_model.sample(batch_size=n), batches))\n",
    "\n",
    "                        all_images = torch.cat(all_images_list, dim = 0)\n",
    "\n",
    "                        utils.save_image(all_images, str(self.results_folder / f'sample-{milestone}.png'), nrow = int(math.sqrt(self.num_samples)))\n",
    "                        \n",
    "                        self.save(milestone)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        accelerator.print('training complete')\n",
    "        \n",
    "    def inference(self, num=1000, n_iter=10, output_path='./submission'):\n",
    "        if not os.path.exists(output_path):\n",
    "            os.mkdir(output_path)\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_iter):\n",
    "                batches = num_to_groups(num // n_iter, 100)\n",
    "                all_images = list(map(lambda n: self.ema.ema_model.sample(batch_size=n), batches))[0]\n",
    "                \n",
    "                for j in range(all_images.size(0)):\n",
    "                    torchvision.utils.save_image(all_images[j], f'{output_path}/{i * 100 + j + 1}.jpg')\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLHSIArLcFK0"
   },
   "source": [
    "## Import Packages and Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: numpy in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "zsh:1: unknown file attribute: 1\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: ninja in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (1.11.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!git clone https://github.com/NVlaRefresh (1 sec) http://localhost:8888/lab?token=1421be6f9845d5405710f19bd3d77885f171e04ef56882f5bs/stylegan2-ada-pytorch.git\n",
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('stylegan2-ada-pytorch')\n",
    "\n",
    "import dnnlib\n",
    "import legacy\n",
    "import torch\n",
    "import os\n",
    "from accelerate import Accelerator\n",
    "from ema_pytorch import EMA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T, utils\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Gradescope – Question 1\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(4096)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        folder,\n",
    "        image_size\n",
    "    ):\n",
    "        self.folder = folder\n",
    "        self.image_size = image_size\n",
    "        self.paths = [p for p in Path(f'{folder}').glob(f'**/*.jpg')]\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomRotation(10),\n",
    "            T.ColorJitter(brightness=0.25, contrast=0.25),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img)\n",
    "\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGANTrainer(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        folder, \n",
    "        image_size, \n",
    "        *,\n",
    "        train_batch_size=16, \n",
    "        gradient_accumulate_every=1, \n",
    "        train_lr=1e-4, \n",
    "        train_num_steps=100000, \n",
    "        ema_update_every=10, \n",
    "        ema_decay=0.995, \n",
    "        save_and_sample_every=1000, \n",
    "        num_samples=25, \n",
    "        results_folder='./results', \n",
    "        split_batches=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        dataloader_config = DataLoaderConfiguration(split_batches=split_batches)\n",
    "        self.accelerator = Accelerator(\n",
    "            dataloader_config=dataloader_config,\n",
    "            mixed_precision='no')\n",
    "        \n",
    "        self.image_size = image_size\n",
    "\n",
    "        # Initialize the generator and discriminator\n",
    "        self.gen = self.create_generator().cuda()\n",
    "        self.dis = self.create_discriminator().cuda()\n",
    "        self.g_optim = torch.optim.Adam(self.gen.parameters(), lr=train_lr, betas=(0.0, 0.99))\n",
    "        self.d_optim = torch.optim.Adam(self.dis.parameters(), lr=train_lr, betas=(0.0, 0.99))\n",
    "        \n",
    "        self.train_num_steps = train_num_steps\n",
    "        self.batch_size = train_batch_size\n",
    "        self.gradient_accumulate_every = gradient_accumulate_every\n",
    "\n",
    "        # Initialize the dataset and dataloader\n",
    "        self.ds = Dataset(folder, image_size)\n",
    "        self.dl = cycle(DataLoader(self.ds, batch_size=train_batch_size, shuffle=True, pin_memory=True, num_workers=os.cpu_count()))\n",
    "\n",
    "        # Initialize the EMA for the generator\n",
    "        self.ema = EMA(self.gen, beta=ema_decay, update_every=ema_update_every).to(self.device)\n",
    "        \n",
    "        self.results_folder = Path(results_folder)\n",
    "        self.results_folder.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.save_and_sample_every = save_and_sample_every\n",
    "        self.num_samples = num_samples\n",
    "        self.step = 0\n",
    "\n",
    "    def create_generator(self):\n",
    "        return dnnlib.util.construct_class_by_name(\n",
    "            class_name='training.networks.Generator',\n",
    "            z_dim=512,\n",
    "            c_dim=0,\n",
    "            w_dim=512,\n",
    "            img_resolution=self.image_size,\n",
    "            img_channels=3\n",
    "        )\n",
    "\n",
    "    def create_discriminator(self):\n",
    "        return dnnlib.util.construct_class_by_name(\n",
    "            class_name='training.networks.Discriminator',\n",
    "            c_dim=0,\n",
    "            img_resolution=self.image_size,\n",
    "            img_channels=3\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.accelerator.device\n",
    "\n",
    "    def save(self, milestone):\n",
    "        if not self.accelerator.is_local_main_process:\n",
    "            return\n",
    "\n",
    "        data = {\n",
    "            'step': self.step,\n",
    "            'gen': self.accelerator.get_state_dict(self.gen),\n",
    "            'dis': self.accelerator.get_state_dict(self.dis),\n",
    "            'g_optim': self.g_optim.state_dict(),\n",
    "            'd_optim': self.d_optim.state_dict(),\n",
    "            'ema': self.ema.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(data, str(self.results_folder / f'model-{milestone}.pt'))\n",
    "\n",
    "    def load(self, ckpt):\n",
    "        data = torch.load(ckpt, map_location=self.device)\n",
    "        self.gen.load_state_dict(data['gen'])\n",
    "        self.dis.load_state_dict(data['dis'])\n",
    "        self.g_optim.load_state_dict(data['g_optim'])\n",
    "        self.d_optim.load_state_dict(data['d_optim'])\n",
    "        self.ema.load_state_dict(data['ema'])\n",
    "        self.step = data['step']\n",
    "\n",
    "    def train(self):\n",
    "        with tqdm(initial=self.step, total=self.train_num_steps, disable=not self.accelerator.is_main_process) as pbar:\n",
    "            while self.step < self.train_num_steps:\n",
    "                total_g_loss = 0.\n",
    "                total_d_loss = 0.\n",
    "\n",
    "                for _ in range(self.gradient_accumulate_every):\n",
    "                    # Get a batch of real images\n",
    "                    real_images = next(self.dl).to(self.device)\n",
    "                    \n",
    "                    # Generate latent vectors\n",
    "                    latent = torch.randn([self.batch_size, self.gen.z_dim]).cuda()\n",
    "                    \n",
    "                    # Generate fake images\n",
    "                    fake_images = self.gen(latent, None)\n",
    "\n",
    "                    # Discriminator logits for real and fake images\n",
    "                    real_logits = self.dis(real_images, None)\n",
    "                    fake_logits = self.dis(fake_images.detach(), None)\n",
    "\n",
    "                    # Discriminator loss\n",
    "                    d_loss = torch.nn.functional.softplus(fake_logits).mean() + torch.nn.functional.softplus(-real_logits).mean()\n",
    "\n",
    "                    # Update discriminator\n",
    "                    self.d_optim.zero_grad()\n",
    "                    self.accelerator.backward(d_loss / self.gradient_accumulate_every)\n",
    "                    self.d_optim.step()\n",
    "                    total_d_loss += d_loss.item()\n",
    "\n",
    "                    # Generator logits for fake images\n",
    "                    fake_logits = self.dis(fake_images, None)\n",
    "\n",
    "                    # Generator loss\n",
    "                    g_loss = torch.nn.functional.softplus(-fake_logits).mean()\n",
    "\n",
    "                    # Update generator\n",
    "                    self.g_optim.zero_grad()\n",
    "                    self.accelerator.backward(g_loss / self.gradient_accumulate_every)\n",
    "                    self.g_optim.step()\n",
    "                    total_g_loss += g_loss.item()\n",
    "\n",
    "                self.ema.update()\n",
    "\n",
    "                pbar.set_description(f'G loss: {total_g_loss:.4f} D loss: {total_d_loss:.4f}')\n",
    "                self.step += 1\n",
    "\n",
    "                if self.step % self.save_and_sample_every == 0:\n",
    "                    self.ema.ema_model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        milestone = self.step // self.save_and_sample_every\n",
    "                        batches = num_to_groups(self.num_samples, self.batch_size)\n",
    "                        all_images_list = list(map(lambda n: self.ema.ema_model(torch.randn([n, self.gen.z_dim]).cuda(), None), batches))\n",
    "                    all_images = torch.cat(all_images_list, dim=0)\n",
    "                    utils.save_image(all_images, str(self.results_folder / f'sample-{milestone}.png'), nrow=int(np.sqrt(self.num_samples)))\n",
    "                    self.save(milestone)\n",
    "                pbar.update(1)\n",
    "\n",
    "        print('Training complete')\n",
    "\n",
    "    def inference(self, num=1000, n_iter=5, output_path='./submission'):\n",
    "        if not os.path.exists(output_path):\n",
    "            os.mkdir(output_path)\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_iter):\n",
    "                latent = torch.randn(num // n_iter, self.gen.z_dim).cuda()\n",
    "                images = self.ema.ema_model(latent, None)\n",
    "                for j, img in enumerate(images):\n",
    "                    utils.save_image(img, f'{output_path}/{i * (num // n_iter) + j + 1}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZM7HR-UInQu"
   },
   "source": [
    "# Training Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                              | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G loss: 5.8996 D loss: 1.1001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [3:14:35<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './faces/faces'\n",
    "IMG_SIZE = 64\n",
    "batch_size = 16\n",
    "train_num_steps = 20000 # 10000\n",
    "lr = 1e-3\n",
    "grad_steps = 1\n",
    "ema_decay = 0.995\n",
    "\n",
    "trainer = StyleGANTrainer(\n",
    "    folder=path,\n",
    "    image_size=IMG_SIZE,\n",
    "    train_batch_size=batch_size,\n",
    "    train_lr=lr,\n",
    "    train_num_steps=train_num_steps,\n",
    "    gradient_accumulate_every=grad_steps,\n",
    "    ema_decay=ema_decay,\n",
    "    save_and_sample_every=1000\n",
    ")\n",
    "\n",
    "os.environ['TORCH_CUDA_ARCH_LIST'] = '8.6' # https://developer.nvidia.com/cuda-gpus\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV7OL7PvInQu"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MHoY_6CrInQv",
    "outputId": "010af6c5-a426-42cd-b560-721fff3baa84"
   },
   "outputs": [],
   "source": [
    "# # Automatically get the last checkpoint\n",
    "last_checkpoint = f'./results/model-{train_num_steps // trainer.save_and_sample_every}.pt'\n",
    "ckpt = last_checkpoint\n",
    "trainer.load(ckpt)\n",
    "trainer.inference(output_path='./submission/boss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GkWpuU-2KzIL",
    "outputId": "2215341d-4f7f-48c3-85ac-403e9ad2cb27",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd ./submission\n",
    "# !tar -zcf ../submission.tgz *.jpg\n",
    "# !cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID & AFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pytorch-fid in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from pytorch-fid) (1.26.4)\n",
      "Requirement already satisfied: pillow in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from pytorch-fid) (10.3.0)\n",
      "Requirement already satisfied: scipy in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from pytorch-fid) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.0.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from pytorch-fid) (2.3.0)\n",
      "Requirement already satisfied: torchvision>=0.2.2 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from pytorch-fid) (0.18.0)\n",
      "Requirement already satisfied: filelock in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.1->pytorch-fid) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from jinja2->torch>=1.0.1->pytorch-fid) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hoperj/miniconda3/envs/UQ/lib/python3.10/site-packages (from sympy->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
      "--2024-06-19 04:34:04--  https://raw.githubusercontent.com/nagadomi/lbpcascade_animeface/master/lbpcascade_animeface.xml\n",
      "Connecting to 127.0.0.1:7890... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 246945 (241K) [text/plain]\n",
      "Saving to: ‘lbpcascade_animeface.xml’\n",
      "\n",
      "lbpcascade_animefac 100%[===================>] 241.16K   494KB/s    in 0.5s    \n",
      "\n",
      "2024-06-19 04:34:05 (494 KB/s) - ‘lbpcascade_animeface.xml’ saved [246945/246945]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-fid\n",
    "!wget https://raw.githubusercontent.com/nagadomi/lbpcascade_animeface/master/lbpcascade_animeface.xml -O lbpcascade_animeface.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pytorch_fid import fid_score\n",
    "import os\n",
    "\n",
    "def calculate_fid(real_images_path, generated_images_path):\n",
    "    \"\"\"\n",
    "    Calculate FID score between real and generated images.\n",
    "    \n",
    "    :param real_images_path: Path to the directory containing real images.\n",
    "    :param generated_images_path: Path to the directory containing generated images.\n",
    "    :return: FID score\n",
    "    \"\"\"\n",
    "    fid = fid_score.calculate_fid_given_paths([real_images_path, generated_images_path], batch_size=50, device='cuda', dims=2048)\n",
    "    return fid\n",
    "\n",
    "def calculate_afd(generated_images_path, save=True):\n",
    "    \"\"\"\n",
    "    Calculate AFD (Anime Face Detection) score for generated images.\n",
    "    \n",
    "    :param generated_images_path: Path to the directory containing generated images.\n",
    "    :return: AFD score (percentage of images detected as anime faces)\n",
    "    \"\"\"\n",
    "    results = yolov8_animeface.predict(generated_images_path, save=save, conf=0.8, iou=0.8, imgsz=64)\n",
    "\n",
    "    anime_faces_detected = 0\n",
    "    total_images = len(results)\n",
    "\n",
    "    for result in results:\n",
    "        if len(result.boxes) > 0:\n",
    "            anime_faces_detected += 1\n",
    "\n",
    "    afd_score = anime_faces_detected / total_images\n",
    "    return afd_score\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1427/1427 [02:32<00:00,  9.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/1.jpg: 64x64 1 face, 6.6ms\n",
      "image 2/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/10.jpg: 64x64 1 face, 6.3ms\n",
      "image 3/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/100.jpg: 64x64 1 face, 6.3ms\n",
      "image 4/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/1000.jpg: 64x64 1 face, 6.3ms\n",
      "image 5/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/101.jpg: 64x64 (no detections), 6.3ms\n",
      "image 6/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/102.jpg: 64x64 1 face, 6.3ms\n",
      "image 7/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/103.jpg: 64x64 1 face, 6.3ms\n",
      "image 8/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/104.jpg: 64x64 (no detections), 6.3ms\n",
      "image 9/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/105.jpg: 64x64 1 face, 6.3ms\n",
      "image 10/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/106.jpg: 64x64 1 face, 6.3ms\n",
      "image 11/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/107.jpg: 64x64 1 face, 6.3ms\n",
      "image 12/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/108.jpg: 64x64 (no detections), 6.4ms\n",
      "image 13/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/109.jpg: 64x64 1 face, 6.3ms\n",
      "image 14/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/11.jpg: 64x64 1 face, 6.3ms\n",
      "image 15/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/110.jpg: 64x64 1 face, 6.3ms\n",
      "image 16/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/111.jpg: 64x64 1 face, 6.3ms\n",
      "image 17/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/112.jpg: 64x64 1 face, 6.3ms\n",
      "image 18/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/113.jpg: 64x64 1 face, 6.3ms\n",
      "image 19/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/114.jpg: 64x64 1 face, 6.1ms\n",
      "image 20/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/115.jpg: 64x64 (no detections), 6.0ms\n",
      "image 21/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/116.jpg: 64x64 1 face, 6.1ms\n",
      "image 22/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/117.jpg: 64x64 1 face, 6.1ms\n",
      "image 23/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/118.jpg: 64x64 1 face, 6.2ms\n",
      "image 24/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/119.jpg: 64x64 1 face, 6.1ms\n",
      "image 25/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/12.jpg: 64x64 1 face, 6.1ms\n",
      "image 26/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/120.jpg: 64x64 1 face, 6.1ms\n",
      "image 27/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/121.jpg: 64x64 (no detections), 6.0ms\n",
      "image 28/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/122.jpg: 64x64 1 face, 6.0ms\n",
      "image 29/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/123.jpg: 64x64 1 face, 6.0ms\n",
      "image 30/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/124.jpg: 64x64 (no detections), 6.1ms\n",
      "image 31/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/125.jpg: 64x64 (no detections), 6.0ms\n",
      "image 32/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/126.jpg: 64x64 1 face, 6.0ms\n",
      "image 33/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/127.jpg: 64x64 1 face, 6.1ms\n",
      "image 34/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/128.jpg: 64x64 1 face, 6.0ms\n",
      "image 35/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/129.jpg: 64x64 (no detections), 6.0ms\n",
      "image 36/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/13.jpg: 64x64 (no detections), 6.0ms\n",
      "image 37/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/130.jpg: 64x64 1 face, 6.0ms\n",
      "image 38/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/131.jpg: 64x64 (no detections), 6.1ms\n",
      "image 39/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/132.jpg: 64x64 1 face, 6.1ms\n",
      "image 40/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/133.jpg: 64x64 1 face, 6.1ms\n",
      "image 41/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/134.jpg: 64x64 1 face, 6.1ms\n",
      "image 42/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/135.jpg: 64x64 1 face, 6.1ms\n",
      "image 43/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/136.jpg: 64x64 1 face, 6.0ms\n",
      "image 44/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/137.jpg: 64x64 1 face, 6.0ms\n",
      "image 45/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/138.jpg: 64x64 1 face, 6.0ms\n",
      "image 46/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/139.jpg: 64x64 1 face, 6.0ms\n",
      "image 47/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/14.jpg: 64x64 1 face, 6.1ms\n",
      "image 48/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/140.jpg: 64x64 1 face, 6.1ms\n",
      "image 49/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/141.jpg: 64x64 1 face, 6.1ms\n",
      "image 50/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/142.jpg: 64x64 1 face, 6.1ms\n",
      "image 51/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/143.jpg: 64x64 1 face, 6.1ms\n",
      "image 52/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/144.jpg: 64x64 1 face, 6.0ms\n",
      "image 53/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/145.jpg: 64x64 1 face, 6.0ms\n",
      "image 54/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/146.jpg: 64x64 1 face, 6.0ms\n",
      "image 55/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/147.jpg: 64x64 1 face, 6.0ms\n",
      "image 56/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/148.jpg: 64x64 1 face, 6.0ms\n",
      "image 57/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/149.jpg: 64x64 (no detections), 6.1ms\n",
      "image 58/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/15.jpg: 64x64 (no detections), 6.1ms\n",
      "image 59/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/150.jpg: 64x64 1 face, 6.1ms\n",
      "image 60/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/151.jpg: 64x64 1 face, 6.1ms\n",
      "image 61/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/152.jpg: 64x64 (no detections), 6.1ms\n",
      "image 62/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/153.jpg: 64x64 (no detections), 6.0ms\n",
      "image 63/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/154.jpg: 64x64 1 face, 6.0ms\n",
      "image 64/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/155.jpg: 64x64 1 face, 6.0ms\n",
      "image 65/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/156.jpg: 64x64 1 face, 6.0ms\n",
      "image 66/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/157.jpg: 64x64 1 face, 6.0ms\n",
      "image 67/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/158.jpg: 64x64 1 face, 6.1ms\n",
      "image 68/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/159.jpg: 64x64 1 face, 6.1ms\n",
      "image 69/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/16.jpg: 64x64 1 face, 6.1ms\n",
      "image 70/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/160.jpg: 64x64 (no detections), 6.1ms\n",
      "image 71/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/161.jpg: 64x64 1 face, 6.0ms\n",
      "image 72/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/162.jpg: 64x64 (no detections), 6.1ms\n",
      "image 73/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/163.jpg: 64x64 1 face, 6.0ms\n",
      "image 74/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/164.jpg: 64x64 1 face, 6.0ms\n",
      "image 75/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/165.jpg: 64x64 1 face, 6.2ms\n",
      "image 76/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/166.jpg: 64x64 1 face, 6.1ms\n",
      "image 77/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/167.jpg: 64x64 1 face, 6.1ms\n",
      "image 78/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/168.jpg: 64x64 1 face, 6.1ms\n",
      "image 79/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/169.jpg: 64x64 1 face, 6.1ms\n",
      "image 80/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/17.jpg: 64x64 1 face, 6.0ms\n",
      "image 81/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/170.jpg: 64x64 (no detections), 6.0ms\n",
      "image 82/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/171.jpg: 64x64 1 face, 6.0ms\n",
      "image 83/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/172.jpg: 64x64 (no detections), 6.1ms\n",
      "image 84/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/173.jpg: 64x64 1 face, 6.1ms\n",
      "image 85/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/174.jpg: 64x64 1 face, 6.1ms\n",
      "image 86/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/175.jpg: 64x64 1 face, 6.1ms\n",
      "image 87/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/176.jpg: 64x64 1 face, 6.2ms\n",
      "image 88/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/177.jpg: 64x64 (no detections), 6.1ms\n",
      "image 89/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/178.jpg: 64x64 1 face, 6.1ms\n",
      "image 90/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/179.jpg: 64x64 1 face, 6.0ms\n",
      "image 91/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/18.jpg: 64x64 1 face, 6.1ms\n",
      "image 92/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/180.jpg: 64x64 1 face, 6.0ms\n",
      "image 93/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/181.jpg: 64x64 1 face, 6.1ms\n",
      "image 94/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/182.jpg: 64x64 1 face, 6.1ms\n",
      "image 95/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/183.jpg: 64x64 (no detections), 6.1ms\n",
      "image 96/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/184.jpg: 64x64 1 face, 6.0ms\n",
      "image 97/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/185.jpg: 64x64 1 face, 6.0ms\n",
      "image 98/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/186.jpg: 64x64 1 face, 6.0ms\n",
      "image 99/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/187.jpg: 64x64 (no detections), 6.0ms\n",
      "image 100/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/188.jpg: 64x64 1 face, 6.1ms\n",
      "image 101/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/189.jpg: 64x64 1 face, 6.1ms\n",
      "image 102/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/19.jpg: 64x64 (no detections), 6.1ms\n",
      "image 103/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/190.jpg: 64x64 1 face, 6.1ms\n",
      "image 104/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/191.jpg: 64x64 (no detections), 6.1ms\n",
      "image 105/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/192.jpg: 64x64 1 face, 6.1ms\n",
      "image 106/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/193.jpg: 64x64 1 face, 6.0ms\n",
      "image 107/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/194.jpg: 64x64 1 face, 6.1ms\n",
      "image 108/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/195.jpg: 64x64 1 face, 6.0ms\n",
      "image 109/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/196.jpg: 64x64 1 face, 6.1ms\n",
      "image 110/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/197.jpg: 64x64 1 face, 6.1ms\n",
      "image 111/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/198.jpg: 64x64 1 face, 6.1ms\n",
      "image 112/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/199.jpg: 64x64 1 face, 6.1ms\n",
      "image 113/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/2.jpg: 64x64 (no detections), 6.0ms\n",
      "image 114/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/20.jpg: 64x64 (no detections), 6.1ms\n",
      "image 115/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/200.jpg: 64x64 1 face, 6.0ms\n",
      "image 116/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/201.jpg: 64x64 1 face, 6.0ms\n",
      "image 117/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/202.jpg: 64x64 1 face, 6.1ms\n",
      "image 118/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/203.jpg: 64x64 1 face, 6.1ms\n",
      "image 119/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/204.jpg: 64x64 (no detections), 6.1ms\n",
      "image 120/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/205.jpg: 64x64 1 face, 6.0ms\n",
      "image 121/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/206.jpg: 64x64 1 face, 6.1ms\n",
      "image 122/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/207.jpg: 64x64 1 face, 6.0ms\n",
      "image 123/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/208.jpg: 64x64 (no detections), 6.1ms\n",
      "image 124/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/209.jpg: 64x64 (no detections), 6.1ms\n",
      "image 125/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/21.jpg: 64x64 1 face, 6.1ms\n",
      "image 126/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/210.jpg: 64x64 1 face, 6.1ms\n",
      "image 127/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/211.jpg: 64x64 1 face, 6.1ms\n",
      "image 128/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/212.jpg: 64x64 1 face, 6.1ms\n",
      "image 129/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/213.jpg: 64x64 1 face, 6.0ms\n",
      "image 130/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/214.jpg: 64x64 1 face, 6.0ms\n",
      "image 131/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/215.jpg: 64x64 1 face, 6.1ms\n",
      "image 132/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/216.jpg: 64x64 1 face, 6.0ms\n",
      "image 133/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/217.jpg: 64x64 (no detections), 6.1ms\n",
      "image 134/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/218.jpg: 64x64 (no detections), 6.0ms\n",
      "image 135/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/219.jpg: 64x64 1 face, 6.1ms\n",
      "image 136/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/22.jpg: 64x64 1 face, 6.1ms\n",
      "image 137/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/220.jpg: 64x64 (no detections), 6.1ms\n",
      "image 138/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/221.jpg: 64x64 1 face, 6.1ms\n",
      "image 139/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/222.jpg: 64x64 1 face, 6.1ms\n",
      "image 140/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/223.jpg: 64x64 1 face, 6.1ms\n",
      "image 141/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/224.jpg: 64x64 1 face, 6.0ms\n",
      "image 142/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/225.jpg: 64x64 1 face, 6.1ms\n",
      "image 143/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/226.jpg: 64x64 1 face, 6.0ms\n",
      "image 144/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/227.jpg: 64x64 1 face, 6.0ms\n",
      "image 145/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/228.jpg: 64x64 1 face, 6.1ms\n",
      "image 146/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/229.jpg: 64x64 1 face, 6.0ms\n",
      "image 147/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/23.jpg: 64x64 1 face, 6.1ms\n",
      "image 148/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/230.jpg: 64x64 1 face, 6.1ms\n",
      "image 149/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/231.jpg: 64x64 1 face, 6.1ms\n",
      "image 150/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/232.jpg: 64x64 1 face, 6.1ms\n",
      "image 151/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/233.jpg: 64x64 1 face, 6.1ms\n",
      "image 152/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/234.jpg: 64x64 1 face, 6.0ms\n",
      "image 153/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/235.jpg: 64x64 1 face, 6.0ms\n",
      "image 154/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/236.jpg: 64x64 (no detections), 6.0ms\n",
      "image 155/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/237.jpg: 64x64 1 face, 6.0ms\n",
      "image 156/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/238.jpg: 64x64 1 face, 6.0ms\n",
      "image 157/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/239.jpg: 64x64 (no detections), 6.1ms\n",
      "image 158/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/24.jpg: 64x64 1 face, 6.2ms\n",
      "image 159/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/240.jpg: 64x64 1 face, 6.1ms\n",
      "image 160/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/241.jpg: 64x64 1 face, 6.1ms\n",
      "image 161/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/242.jpg: 64x64 1 face, 6.1ms\n",
      "image 162/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/243.jpg: 64x64 1 face, 6.1ms\n",
      "image 163/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/244.jpg: 64x64 1 face, 6.1ms\n",
      "image 164/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/245.jpg: 64x64 1 face, 6.0ms\n",
      "image 165/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/246.jpg: 64x64 1 face, 6.0ms\n",
      "image 166/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/247.jpg: 64x64 1 face, 6.0ms\n",
      "image 167/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/248.jpg: 64x64 1 face, 6.1ms\n",
      "image 168/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/249.jpg: 64x64 1 face, 6.1ms\n",
      "image 169/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/25.jpg: 64x64 1 face, 6.1ms\n",
      "image 170/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/250.jpg: 64x64 1 face, 6.0ms\n",
      "image 171/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/251.jpg: 64x64 1 face, 6.0ms\n",
      "image 172/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/252.jpg: 64x64 1 face, 6.1ms\n",
      "image 173/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/253.jpg: 64x64 1 face, 6.0ms\n",
      "image 174/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/254.jpg: 64x64 1 face, 6.2ms\n",
      "image 175/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/255.jpg: 64x64 1 face, 6.1ms\n",
      "image 176/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/256.jpg: 64x64 1 face, 6.1ms\n",
      "image 177/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/257.jpg: 64x64 1 face, 6.1ms\n",
      "image 178/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/258.jpg: 64x64 1 face, 6.1ms\n",
      "image 179/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/259.jpg: 64x64 1 face, 6.0ms\n",
      "image 180/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/26.jpg: 64x64 1 face, 6.1ms\n",
      "image 181/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/260.jpg: 64x64 (no detections), 6.1ms\n",
      "image 182/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/261.jpg: 64x64 1 face, 6.1ms\n",
      "image 183/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/262.jpg: 64x64 1 face, 6.1ms\n",
      "image 184/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/263.jpg: 64x64 1 face, 6.0ms\n",
      "image 185/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/264.jpg: 64x64 1 face, 6.0ms\n",
      "image 186/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/265.jpg: 64x64 1 face, 6.1ms\n",
      "image 187/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/266.jpg: 64x64 1 face, 6.1ms\n",
      "image 188/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/267.jpg: 64x64 1 face, 6.1ms\n",
      "image 189/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/268.jpg: 64x64 1 face, 6.1ms\n",
      "image 190/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/269.jpg: 64x64 1 face, 6.1ms\n",
      "image 191/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/27.jpg: 64x64 1 face, 6.1ms\n",
      "image 192/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/270.jpg: 64x64 1 face, 6.1ms\n",
      "image 193/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/271.jpg: 64x64 1 face, 6.0ms\n",
      "image 194/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/272.jpg: 64x64 1 face, 6.1ms\n",
      "image 195/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/273.jpg: 64x64 1 face, 6.1ms\n",
      "image 196/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/274.jpg: 64x64 1 face, 6.1ms\n",
      "image 197/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/275.jpg: 64x64 1 face, 6.1ms\n",
      "image 198/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/276.jpg: 64x64 1 face, 6.1ms\n",
      "image 199/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/277.jpg: 64x64 1 face, 6.1ms\n",
      "image 200/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/278.jpg: 64x64 1 face, 6.0ms\n",
      "image 201/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/279.jpg: 64x64 1 face, 6.0ms\n",
      "image 202/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/28.jpg: 64x64 1 face, 6.0ms\n",
      "image 203/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/280.jpg: 64x64 1 face, 6.0ms\n",
      "image 204/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/281.jpg: 64x64 1 face, 6.1ms\n",
      "image 205/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/282.jpg: 64x64 1 face, 6.1ms\n",
      "image 206/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/283.jpg: 64x64 1 face, 6.1ms\n",
      "image 207/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/284.jpg: 64x64 1 face, 6.0ms\n",
      "image 208/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/285.jpg: 64x64 1 face, 6.0ms\n",
      "image 209/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/286.jpg: 64x64 1 face, 6.0ms\n",
      "image 210/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/287.jpg: 64x64 1 face, 6.0ms\n",
      "image 211/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/288.jpg: 64x64 (no detections), 6.1ms\n",
      "image 212/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/289.jpg: 64x64 1 face, 6.1ms\n",
      "image 213/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/29.jpg: 64x64 1 face, 6.1ms\n",
      "image 214/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/290.jpg: 64x64 (no detections), 6.1ms\n",
      "image 215/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/291.jpg: 64x64 1 face, 6.1ms\n",
      "image 216/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/292.jpg: 64x64 1 face, 6.1ms\n",
      "image 217/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/293.jpg: 64x64 1 face, 6.1ms\n",
      "image 218/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/294.jpg: 64x64 1 face, 6.1ms\n",
      "image 219/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/295.jpg: 64x64 (no detections), 6.0ms\n",
      "image 220/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/296.jpg: 64x64 1 face, 6.1ms\n",
      "image 221/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/297.jpg: 64x64 1 face, 6.0ms\n",
      "image 222/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/298.jpg: 64x64 1 face, 6.0ms\n",
      "image 223/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/299.jpg: 64x64 (no detections), 6.1ms\n",
      "image 224/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/3.jpg: 64x64 1 face, 6.1ms\n",
      "image 225/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/30.jpg: 64x64 1 face, 6.1ms\n",
      "image 226/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/300.jpg: 64x64 1 face, 6.1ms\n",
      "image 227/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/301.jpg: 64x64 1 face, 6.1ms\n",
      "image 228/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/302.jpg: 64x64 (no detections), 6.1ms\n",
      "image 229/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/303.jpg: 64x64 1 face, 6.0ms\n",
      "image 230/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/304.jpg: 64x64 1 face, 6.0ms\n",
      "image 231/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/305.jpg: 64x64 1 face, 6.0ms\n",
      "image 232/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/306.jpg: 64x64 1 face, 6.1ms\n",
      "image 233/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/307.jpg: 64x64 1 face, 6.0ms\n",
      "image 234/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/308.jpg: 64x64 (no detections), 6.1ms\n",
      "image 235/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/309.jpg: 64x64 1 face, 6.1ms\n",
      "image 236/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/31.jpg: 64x64 1 face, 6.1ms\n",
      "image 237/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/310.jpg: 64x64 1 face, 6.1ms\n",
      "image 238/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/311.jpg: 64x64 1 face, 6.1ms\n",
      "image 239/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/312.jpg: 64x64 1 face, 6.1ms\n",
      "image 240/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/313.jpg: 64x64 1 face, 6.1ms\n",
      "image 241/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/314.jpg: 64x64 (no detections), 6.1ms\n",
      "image 242/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/315.jpg: 64x64 1 face, 6.1ms\n",
      "image 243/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/316.jpg: 64x64 1 face, 6.1ms\n",
      "image 244/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/317.jpg: 64x64 (no detections), 6.1ms\n",
      "image 245/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/318.jpg: 64x64 1 face, 6.1ms\n",
      "image 246/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/319.jpg: 64x64 (no detections), 6.1ms\n",
      "image 247/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/32.jpg: 64x64 1 face, 6.1ms\n",
      "image 248/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/320.jpg: 64x64 (no detections), 6.1ms\n",
      "image 249/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/321.jpg: 64x64 1 face, 6.0ms\n",
      "image 250/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/322.jpg: 64x64 1 face, 6.1ms\n",
      "image 251/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/323.jpg: 64x64 1 face, 6.1ms\n",
      "image 252/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/324.jpg: 64x64 1 face, 6.1ms\n",
      "image 253/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/325.jpg: 64x64 1 face, 6.0ms\n",
      "image 254/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/326.jpg: 64x64 1 face, 6.0ms\n",
      "image 255/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/327.jpg: 64x64 (no detections), 6.1ms\n",
      "image 256/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/328.jpg: 64x64 1 face, 6.0ms\n",
      "image 257/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/329.jpg: 64x64 (no detections), 6.1ms\n",
      "image 258/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/33.jpg: 64x64 1 face, 6.1ms\n",
      "image 259/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/330.jpg: 64x64 1 face, 6.1ms\n",
      "image 260/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/331.jpg: 64x64 1 face, 6.1ms\n",
      "image 261/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/332.jpg: 64x64 1 face, 6.1ms\n",
      "image 262/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/333.jpg: 64x64 1 face, 6.1ms\n",
      "image 263/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/334.jpg: 64x64 1 face, 6.0ms\n",
      "image 264/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/335.jpg: 64x64 1 face, 6.1ms\n",
      "image 265/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/336.jpg: 64x64 1 face, 6.0ms\n",
      "image 266/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/337.jpg: 64x64 1 face, 6.0ms\n",
      "image 267/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/338.jpg: 64x64 1 face, 6.0ms\n",
      "image 268/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/339.jpg: 64x64 1 face, 6.1ms\n",
      "image 269/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/34.jpg: 64x64 (no detections), 6.1ms\n",
      "image 270/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/340.jpg: 64x64 1 face, 6.0ms\n",
      "image 271/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/341.jpg: 64x64 1 face, 6.1ms\n",
      "image 272/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/342.jpg: 64x64 1 face, 6.0ms\n",
      "image 273/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/343.jpg: 64x64 (no detections), 6.0ms\n",
      "image 274/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/344.jpg: 64x64 1 face, 6.1ms\n",
      "image 275/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/345.jpg: 64x64 1 face, 6.1ms\n",
      "image 276/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/346.jpg: 64x64 1 face, 6.1ms\n",
      "image 277/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/347.jpg: 64x64 1 face, 6.0ms\n",
      "image 278/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/348.jpg: 64x64 1 face, 6.1ms\n",
      "image 279/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/349.jpg: 64x64 (no detections), 6.0ms\n",
      "image 280/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/35.jpg: 64x64 1 face, 6.0ms\n",
      "image 281/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/350.jpg: 64x64 1 face, 6.0ms\n",
      "image 282/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/351.jpg: 64x64 1 face, 6.1ms\n",
      "image 283/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/352.jpg: 64x64 1 face, 6.1ms\n",
      "image 284/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/353.jpg: 64x64 1 face, 6.0ms\n",
      "image 285/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/354.jpg: 64x64 1 face, 6.0ms\n",
      "image 286/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/355.jpg: 64x64 1 face, 6.0ms\n",
      "image 287/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/356.jpg: 64x64 1 face, 6.0ms\n",
      "image 288/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/357.jpg: 64x64 1 face, 6.0ms\n",
      "image 289/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/358.jpg: 64x64 1 face, 6.0ms\n",
      "image 290/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/359.jpg: 64x64 1 face, 6.1ms\n",
      "image 291/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/36.jpg: 64x64 1 face, 6.1ms\n",
      "image 292/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/360.jpg: 64x64 1 face, 6.1ms\n",
      "image 293/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/361.jpg: 64x64 1 face, 6.0ms\n",
      "image 294/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/362.jpg: 64x64 1 face, 6.0ms\n",
      "image 295/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/363.jpg: 64x64 1 face, 6.0ms\n",
      "image 296/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/364.jpg: 64x64 1 face, 6.0ms\n",
      "image 297/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/365.jpg: 64x64 1 face, 6.1ms\n",
      "image 298/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/366.jpg: 64x64 1 face, 6.1ms\n",
      "image 299/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/367.jpg: 64x64 1 face, 6.1ms\n",
      "image 300/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/368.jpg: 64x64 (no detections), 6.0ms\n",
      "image 301/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/369.jpg: 64x64 1 face, 6.1ms\n",
      "image 302/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/37.jpg: 64x64 1 face, 6.1ms\n",
      "image 303/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/370.jpg: 64x64 1 face, 6.1ms\n",
      "image 304/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/371.jpg: 64x64 1 face, 6.1ms\n",
      "image 305/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/372.jpg: 64x64 1 face, 6.1ms\n",
      "image 306/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/373.jpg: 64x64 (no detections), 6.1ms\n",
      "image 307/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/374.jpg: 64x64 1 face, 6.1ms\n",
      "image 308/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/375.jpg: 64x64 (no detections), 6.1ms\n",
      "image 309/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/376.jpg: 64x64 1 face, 6.1ms\n",
      "image 310/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/377.jpg: 64x64 1 face, 6.1ms\n",
      "image 311/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/378.jpg: 64x64 1 face, 6.1ms\n",
      "image 312/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/379.jpg: 64x64 1 face, 6.1ms\n",
      "image 313/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/38.jpg: 64x64 1 face, 6.1ms\n",
      "image 314/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/380.jpg: 64x64 1 face, 6.1ms\n",
      "image 315/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/381.jpg: 64x64 1 face, 6.1ms\n",
      "image 316/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/382.jpg: 64x64 (no detections), 6.0ms\n",
      "image 317/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/383.jpg: 64x64 1 face, 6.0ms\n",
      "image 318/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/384.jpg: 64x64 1 face, 6.0ms\n",
      "image 319/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/385.jpg: 64x64 1 face, 6.1ms\n",
      "image 320/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/386.jpg: 64x64 1 face, 6.1ms\n",
      "image 321/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/387.jpg: 64x64 1 face, 6.1ms\n",
      "image 322/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/388.jpg: 64x64 1 face, 6.1ms\n",
      "image 323/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/389.jpg: 64x64 1 face, 6.1ms\n",
      "image 324/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/39.jpg: 64x64 1 face, 6.1ms\n",
      "image 325/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/390.jpg: 64x64 (no detections), 6.0ms\n",
      "image 326/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/391.jpg: 64x64 1 face, 6.0ms\n",
      "image 327/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/392.jpg: 64x64 1 face, 6.1ms\n",
      "image 328/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/393.jpg: 64x64 1 face, 6.1ms\n",
      "image 329/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/394.jpg: 64x64 1 face, 6.1ms\n",
      "image 330/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/395.jpg: 64x64 1 face, 6.0ms\n",
      "image 331/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/396.jpg: 64x64 1 face, 6.1ms\n",
      "image 332/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/397.jpg: 64x64 1 face, 6.0ms\n",
      "image 333/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/398.jpg: 64x64 (no detections), 6.0ms\n",
      "image 334/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/399.jpg: 64x64 1 face, 6.1ms\n",
      "image 335/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/4.jpg: 64x64 1 face, 6.1ms\n",
      "image 336/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/40.jpg: 64x64 (no detections), 6.2ms\n",
      "image 337/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/400.jpg: 64x64 1 face, 6.1ms\n",
      "image 338/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/401.jpg: 64x64 1 face, 6.1ms\n",
      "image 339/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/402.jpg: 64x64 1 face, 6.1ms\n",
      "image 340/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/403.jpg: 64x64 (no detections), 6.1ms\n",
      "image 341/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/404.jpg: 64x64 (no detections), 6.0ms\n",
      "image 342/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/405.jpg: 64x64 1 face, 6.0ms\n",
      "image 343/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/406.jpg: 64x64 (no detections), 6.1ms\n",
      "image 344/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/407.jpg: 64x64 1 face, 6.0ms\n",
      "image 345/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/408.jpg: 64x64 1 face, 6.2ms\n",
      "image 346/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/409.jpg: 64x64 1 face, 6.1ms\n",
      "image 347/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/41.jpg: 64x64 1 face, 6.1ms\n",
      "image 348/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/410.jpg: 64x64 (no detections), 6.1ms\n",
      "image 349/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/411.jpg: 64x64 1 face, 6.0ms\n",
      "image 350/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/412.jpg: 64x64 (no detections), 6.0ms\n",
      "image 351/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/413.jpg: 64x64 1 face, 6.0ms\n",
      "image 352/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/414.jpg: 64x64 1 face, 6.1ms\n",
      "image 353/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/415.jpg: 64x64 (no detections), 6.1ms\n",
      "image 354/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/416.jpg: 64x64 1 face, 6.1ms\n",
      "image 355/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/417.jpg: 64x64 (no detections), 6.1ms\n",
      "image 356/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/418.jpg: 64x64 1 face, 6.1ms\n",
      "image 357/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/419.jpg: 64x64 1 face, 6.1ms\n",
      "image 358/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/42.jpg: 64x64 (no detections), 6.1ms\n",
      "image 359/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/420.jpg: 64x64 1 face, 6.1ms\n",
      "image 360/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/421.jpg: 64x64 1 face, 6.0ms\n",
      "image 361/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/422.jpg: 64x64 1 face, 6.1ms\n",
      "image 362/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/423.jpg: 64x64 1 face, 6.0ms\n",
      "image 363/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/424.jpg: 64x64 1 face, 6.0ms\n",
      "image 364/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/425.jpg: 64x64 1 face, 6.1ms\n",
      "image 365/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/426.jpg: 64x64 1 face, 6.1ms\n",
      "image 366/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/427.jpg: 64x64 (no detections), 6.1ms\n",
      "image 367/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/428.jpg: 64x64 1 face, 6.0ms\n",
      "image 368/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/429.jpg: 64x64 1 face, 6.1ms\n",
      "image 369/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/43.jpg: 64x64 1 face, 6.1ms\n",
      "image 370/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/430.jpg: 64x64 1 face, 6.0ms\n",
      "image 371/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/431.jpg: 64x64 1 face, 6.1ms\n",
      "image 372/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/432.jpg: 64x64 1 face, 6.1ms\n",
      "image 373/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/433.jpg: 64x64 1 face, 6.1ms\n",
      "image 374/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/434.jpg: 64x64 1 face, 6.0ms\n",
      "image 375/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/435.jpg: 64x64 1 face, 6.0ms\n",
      "image 376/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/436.jpg: 64x64 1 face, 6.0ms\n",
      "image 377/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/437.jpg: 64x64 1 face, 6.0ms\n",
      "image 378/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/438.jpg: 64x64 (no detections), 6.1ms\n",
      "image 379/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/439.jpg: 64x64 1 face, 6.1ms\n",
      "image 380/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/44.jpg: 64x64 1 face, 6.1ms\n",
      "image 381/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/440.jpg: 64x64 1 face, 6.1ms\n",
      "image 382/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/441.jpg: 64x64 1 face, 6.1ms\n",
      "image 383/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/442.jpg: 64x64 1 face, 6.1ms\n",
      "image 384/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/443.jpg: 64x64 1 face, 6.1ms\n",
      "image 385/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/444.jpg: 64x64 1 face, 6.1ms\n",
      "image 386/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/445.jpg: 64x64 1 face, 6.1ms\n",
      "image 387/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/446.jpg: 64x64 1 face, 6.1ms\n",
      "image 388/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/447.jpg: 64x64 1 face, 6.0ms\n",
      "image 389/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/448.jpg: 64x64 1 face, 6.2ms\n",
      "image 390/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/449.jpg: 64x64 (no detections), 6.1ms\n",
      "image 391/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/45.jpg: 64x64 1 face, 6.1ms\n",
      "image 392/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/450.jpg: 64x64 1 face, 6.0ms\n",
      "image 393/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/451.jpg: 64x64 1 face, 6.0ms\n",
      "image 394/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/452.jpg: 64x64 (no detections), 6.0ms\n",
      "image 395/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/453.jpg: 64x64 1 face, 6.0ms\n",
      "image 396/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/454.jpg: 64x64 1 face, 6.1ms\n",
      "image 397/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/455.jpg: 64x64 1 face, 6.1ms\n",
      "image 398/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/456.jpg: 64x64 1 face, 6.1ms\n",
      "image 399/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/457.jpg: 64x64 1 face, 6.1ms\n",
      "image 400/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/458.jpg: 64x64 (no detections), 6.1ms\n",
      "image 401/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/459.jpg: 64x64 1 face, 6.0ms\n",
      "image 402/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/46.jpg: 64x64 1 face, 6.0ms\n",
      "image 403/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/460.jpg: 64x64 1 face, 6.1ms\n",
      "image 404/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/461.jpg: 64x64 1 face, 6.1ms\n",
      "image 405/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/462.jpg: 64x64 1 face, 6.1ms\n",
      "image 406/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/463.jpg: 64x64 1 face, 6.1ms\n",
      "image 407/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/464.jpg: 64x64 1 face, 6.1ms\n",
      "image 408/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/465.jpg: 64x64 1 face, 6.1ms\n",
      "image 409/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/466.jpg: 64x64 1 face, 6.1ms\n",
      "image 410/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/467.jpg: 64x64 1 face, 6.1ms\n",
      "image 411/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/468.jpg: 64x64 1 face, 6.1ms\n",
      "image 412/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/469.jpg: 64x64 (no detections), 6.2ms\n",
      "image 413/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/47.jpg: 64x64 1 face, 6.1ms\n",
      "image 414/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/470.jpg: 64x64 1 face, 6.1ms\n",
      "image 415/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/471.jpg: 64x64 1 face, 6.1ms\n",
      "image 416/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/472.jpg: 64x64 1 face, 6.1ms\n",
      "image 417/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/473.jpg: 64x64 1 face, 6.2ms\n",
      "image 418/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/474.jpg: 64x64 1 face, 6.0ms\n",
      "image 419/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/475.jpg: 64x64 1 face, 6.0ms\n",
      "image 420/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/476.jpg: 64x64 1 face, 6.0ms\n",
      "image 421/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/477.jpg: 64x64 1 face, 6.0ms\n",
      "image 422/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/478.jpg: 64x64 1 face, 6.1ms\n",
      "image 423/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/479.jpg: 64x64 1 face, 6.1ms\n",
      "image 424/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/48.jpg: 64x64 (no detections), 6.1ms\n",
      "image 425/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/480.jpg: 64x64 1 face, 6.1ms\n",
      "image 426/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/481.jpg: 64x64 1 face, 6.1ms\n",
      "image 427/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/482.jpg: 64x64 (no detections), 6.1ms\n",
      "image 428/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/483.jpg: 64x64 1 face, 6.1ms\n",
      "image 429/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/484.jpg: 64x64 (no detections), 6.1ms\n",
      "image 430/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/485.jpg: 64x64 1 face, 6.1ms\n",
      "image 431/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/486.jpg: 64x64 1 face, 6.1ms\n",
      "image 432/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/487.jpg: 64x64 1 face, 6.1ms\n",
      "image 433/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/488.jpg: 64x64 1 face, 6.1ms\n",
      "image 434/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/489.jpg: 64x64 1 face, 6.1ms\n",
      "image 435/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/49.jpg: 64x64 (no detections), 6.0ms\n",
      "image 436/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/490.jpg: 64x64 1 face, 6.0ms\n",
      "image 437/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/491.jpg: 64x64 1 face, 6.1ms\n",
      "image 438/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/492.jpg: 64x64 1 face, 6.0ms\n",
      "image 439/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/493.jpg: 64x64 (no detections), 6.2ms\n",
      "image 440/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/494.jpg: 64x64 1 face, 6.1ms\n",
      "image 441/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/495.jpg: 64x64 1 face, 6.2ms\n",
      "image 442/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/496.jpg: 64x64 1 face, 6.1ms\n",
      "image 443/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/497.jpg: 64x64 1 face, 6.1ms\n",
      "image 444/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/498.jpg: 64x64 1 face, 6.1ms\n",
      "image 445/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/499.jpg: 64x64 1 face, 6.1ms\n",
      "image 446/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/5.jpg: 64x64 1 face, 6.1ms\n",
      "image 447/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/50.jpg: 64x64 1 face, 6.1ms\n",
      "image 448/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/500.jpg: 64x64 1 face, 6.1ms\n",
      "image 449/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/501.jpg: 64x64 1 face, 6.1ms\n",
      "image 450/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/502.jpg: 64x64 (no detections), 6.1ms\n",
      "image 451/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/503.jpg: 64x64 1 face, 6.1ms\n",
      "image 452/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/504.jpg: 64x64 1 face, 6.0ms\n",
      "image 453/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/505.jpg: 64x64 (no detections), 6.1ms\n",
      "image 454/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/506.jpg: 64x64 1 face, 6.1ms\n",
      "image 455/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/507.jpg: 64x64 1 face, 6.1ms\n",
      "image 456/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/508.jpg: 64x64 (no detections), 6.1ms\n",
      "image 457/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/509.jpg: 64x64 1 face, 6.1ms\n",
      "image 458/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/51.jpg: 64x64 1 face, 6.2ms\n",
      "image 459/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/510.jpg: 64x64 (no detections), 6.1ms\n",
      "image 460/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/511.jpg: 64x64 1 face, 6.1ms\n",
      "image 461/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/512.jpg: 64x64 1 face, 6.1ms\n",
      "image 462/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/513.jpg: 64x64 1 face, 6.1ms\n",
      "image 463/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/514.jpg: 64x64 1 face, 6.1ms\n",
      "image 464/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/515.jpg: 64x64 1 face, 6.0ms\n",
      "image 465/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/516.jpg: 64x64 1 face, 6.1ms\n",
      "image 466/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/517.jpg: 64x64 (no detections), 6.1ms\n",
      "image 467/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/518.jpg: 64x64 1 face, 6.1ms\n",
      "image 468/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/519.jpg: 64x64 (no detections), 6.2ms\n",
      "image 469/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/52.jpg: 64x64 (no detections), 6.2ms\n",
      "image 470/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/520.jpg: 64x64 1 face, 6.1ms\n",
      "image 471/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/521.jpg: 64x64 1 face, 6.1ms\n",
      "image 472/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/522.jpg: 64x64 (no detections), 6.1ms\n",
      "image 473/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/523.jpg: 64x64 (no detections), 6.1ms\n",
      "image 474/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/524.jpg: 64x64 1 face, 6.1ms\n",
      "image 475/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/525.jpg: 64x64 1 face, 6.0ms\n",
      "image 476/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/526.jpg: 64x64 1 face, 6.1ms\n",
      "image 477/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/527.jpg: 64x64 (no detections), 6.0ms\n",
      "image 478/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/528.jpg: 64x64 (no detections), 6.1ms\n",
      "image 479/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/529.jpg: 64x64 (no detections), 6.1ms\n",
      "image 480/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/53.jpg: 64x64 1 face, 6.1ms\n",
      "image 481/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/530.jpg: 64x64 1 face, 6.1ms\n",
      "image 482/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/531.jpg: 64x64 1 face, 6.0ms\n",
      "image 483/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/532.jpg: 64x64 1 face, 6.1ms\n",
      "image 484/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/533.jpg: 64x64 1 face, 6.0ms\n",
      "image 485/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/534.jpg: 64x64 (no detections), 6.0ms\n",
      "image 486/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/535.jpg: 64x64 1 face, 6.1ms\n",
      "image 487/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/536.jpg: 64x64 1 face, 6.1ms\n",
      "image 488/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/537.jpg: 64x64 1 face, 6.1ms\n",
      "image 489/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/538.jpg: 64x64 1 face, 6.1ms\n",
      "image 490/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/539.jpg: 64x64 (no detections), 6.1ms\n",
      "image 491/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/54.jpg: 64x64 1 face, 6.0ms\n",
      "image 492/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/540.jpg: 64x64 1 face, 6.0ms\n",
      "image 493/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/541.jpg: 64x64 1 face, 6.0ms\n",
      "image 494/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/542.jpg: 64x64 1 face, 6.0ms\n",
      "image 495/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/543.jpg: 64x64 1 face, 6.1ms\n",
      "image 496/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/544.jpg: 64x64 1 face, 6.1ms\n",
      "image 497/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/545.jpg: 64x64 1 face, 6.1ms\n",
      "image 498/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/546.jpg: 64x64 1 face, 6.1ms\n",
      "image 499/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/547.jpg: 64x64 1 face, 6.0ms\n",
      "image 500/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/548.jpg: 64x64 1 face, 6.2ms\n",
      "image 501/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/549.jpg: 64x64 1 face, 6.1ms\n",
      "image 502/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/55.jpg: 64x64 1 face, 6.1ms\n",
      "image 503/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/550.jpg: 64x64 1 face, 6.1ms\n",
      "image 504/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/551.jpg: 64x64 1 face, 6.1ms\n",
      "image 505/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/552.jpg: 64x64 1 face, 6.1ms\n",
      "image 506/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/553.jpg: 64x64 1 face, 6.1ms\n",
      "image 507/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/554.jpg: 64x64 1 face, 6.1ms\n",
      "image 508/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/555.jpg: 64x64 1 face, 6.1ms\n",
      "image 509/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/556.jpg: 64x64 1 face, 6.1ms\n",
      "image 510/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/557.jpg: 64x64 1 face, 6.1ms\n",
      "image 511/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/558.jpg: 64x64 1 face, 6.1ms\n",
      "image 512/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/559.jpg: 64x64 1 face, 6.1ms\n",
      "image 513/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/56.jpg: 64x64 1 face, 6.2ms\n",
      "image 514/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/560.jpg: 64x64 1 face, 6.1ms\n",
      "image 515/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/561.jpg: 64x64 1 face, 6.1ms\n",
      "image 516/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/562.jpg: 64x64 1 face, 6.1ms\n",
      "image 517/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/563.jpg: 64x64 1 face, 6.1ms\n",
      "image 518/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/564.jpg: 64x64 (no detections), 6.1ms\n",
      "image 519/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/565.jpg: 64x64 1 face, 6.1ms\n",
      "image 520/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/566.jpg: 64x64 1 face, 6.1ms\n",
      "image 521/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/567.jpg: 64x64 1 face, 6.1ms\n",
      "image 522/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/568.jpg: 64x64 1 face, 6.1ms\n",
      "image 523/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/569.jpg: 64x64 1 face, 6.1ms\n",
      "image 524/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/57.jpg: 64x64 1 face, 6.1ms\n",
      "image 525/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/570.jpg: 64x64 1 face, 6.1ms\n",
      "image 526/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/571.jpg: 64x64 1 face, 6.1ms\n",
      "image 527/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/572.jpg: 64x64 (no detections), 6.1ms\n",
      "image 528/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/573.jpg: 64x64 1 face, 6.1ms\n",
      "image 529/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/574.jpg: 64x64 1 face, 6.2ms\n",
      "image 530/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/575.jpg: 64x64 1 face, 6.1ms\n",
      "image 531/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/576.jpg: 64x64 1 face, 6.1ms\n",
      "image 532/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/577.jpg: 64x64 1 face, 6.1ms\n",
      "image 533/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/578.jpg: 64x64 (no detections), 6.1ms\n",
      "image 534/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/579.jpg: 64x64 (no detections), 6.0ms\n",
      "image 535/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/58.jpg: 64x64 1 face, 6.1ms\n",
      "image 536/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/580.jpg: 64x64 (no detections), 6.2ms\n",
      "image 537/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/581.jpg: 64x64 1 face, 6.1ms\n",
      "image 538/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/582.jpg: 64x64 1 face, 6.1ms\n",
      "image 539/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/583.jpg: 64x64 (no detections), 6.1ms\n",
      "image 540/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/584.jpg: 64x64 1 face, 6.1ms\n",
      "image 541/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/585.jpg: 64x64 1 face, 6.1ms\n",
      "image 542/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/586.jpg: 64x64 1 face, 6.1ms\n",
      "image 543/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/587.jpg: 64x64 1 face, 6.1ms\n",
      "image 544/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/588.jpg: 64x64 1 face, 6.0ms\n",
      "image 545/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/589.jpg: 64x64 1 face, 6.1ms\n",
      "image 546/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/59.jpg: 64x64 1 face, 6.1ms\n",
      "image 547/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/590.jpg: 64x64 1 face, 6.1ms\n",
      "image 548/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/591.jpg: 64x64 (no detections), 6.1ms\n",
      "image 549/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/592.jpg: 64x64 1 face, 6.0ms\n",
      "image 550/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/593.jpg: 64x64 1 face, 6.0ms\n",
      "image 551/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/594.jpg: 64x64 1 face, 6.0ms\n",
      "image 552/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/595.jpg: 64x64 1 face, 6.0ms\n",
      "image 553/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/596.jpg: 64x64 1 face, 7.4ms\n",
      "image 554/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/597.jpg: 64x64 1 face, 6.1ms\n",
      "image 555/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/598.jpg: 64x64 1 face, 6.1ms\n",
      "image 556/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/599.jpg: 64x64 1 face, 6.1ms\n",
      "image 557/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/6.jpg: 64x64 (no detections), 6.0ms\n",
      "image 558/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/60.jpg: 64x64 1 face, 6.0ms\n",
      "image 559/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/600.jpg: 64x64 1 face, 6.1ms\n",
      "image 560/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/601.jpg: 64x64 1 face, 6.1ms\n",
      "image 561/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/602.jpg: 64x64 1 face, 6.1ms\n",
      "image 562/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/603.jpg: 64x64 1 face, 6.1ms\n",
      "image 563/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/604.jpg: 64x64 1 face, 6.1ms\n",
      "image 564/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/605.jpg: 64x64 (no detections), 6.0ms\n",
      "image 565/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/606.jpg: 64x64 1 face, 6.0ms\n",
      "image 566/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/607.jpg: 64x64 1 face, 6.0ms\n",
      "image 567/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/608.jpg: 64x64 1 face, 6.1ms\n",
      "image 568/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/609.jpg: 64x64 1 face, 6.1ms\n",
      "image 569/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/61.jpg: 64x64 1 face, 6.1ms\n",
      "image 570/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/610.jpg: 64x64 1 face, 6.6ms\n",
      "image 571/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/611.jpg: 64x64 1 face, 6.6ms\n",
      "image 572/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/612.jpg: 64x64 (no detections), 6.6ms\n",
      "image 573/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/613.jpg: 64x64 1 face, 6.5ms\n",
      "image 574/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/614.jpg: 64x64 1 face, 6.4ms\n",
      "image 575/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/615.jpg: 64x64 1 face, 6.4ms\n",
      "image 576/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/616.jpg: 64x64 1 face, 6.3ms\n",
      "image 577/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/617.jpg: 64x64 1 face, 6.2ms\n",
      "image 578/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/618.jpg: 64x64 1 face, 6.2ms\n",
      "image 579/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/619.jpg: 64x64 1 face, 6.1ms\n",
      "image 580/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/62.jpg: 64x64 1 face, 6.0ms\n",
      "image 581/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/620.jpg: 64x64 1 face, 6.1ms\n",
      "image 582/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/621.jpg: 64x64 (no detections), 6.1ms\n",
      "image 583/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/622.jpg: 64x64 1 face, 6.1ms\n",
      "image 584/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/623.jpg: 64x64 1 face, 6.1ms\n",
      "image 585/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/624.jpg: 64x64 1 face, 6.1ms\n",
      "image 586/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/625.jpg: 64x64 1 face, 6.1ms\n",
      "image 587/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/626.jpg: 64x64 1 face, 6.1ms\n",
      "image 588/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/627.jpg: 64x64 (no detections), 6.0ms\n",
      "image 589/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/628.jpg: 64x64 1 face, 6.1ms\n",
      "image 590/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/629.jpg: 64x64 1 face, 6.1ms\n",
      "image 591/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/63.jpg: 64x64 1 face, 6.1ms\n",
      "image 592/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/630.jpg: 64x64 1 face, 6.1ms\n",
      "image 593/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/631.jpg: 64x64 1 face, 6.1ms\n",
      "image 594/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/632.jpg: 64x64 1 face, 6.1ms\n",
      "image 595/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/633.jpg: 64x64 1 face, 6.0ms\n",
      "image 596/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/634.jpg: 64x64 (no detections), 6.1ms\n",
      "image 597/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/635.jpg: 64x64 1 face, 6.1ms\n",
      "image 598/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/636.jpg: 64x64 1 face, 6.0ms\n",
      "image 599/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/637.jpg: 64x64 (no detections), 6.1ms\n",
      "image 600/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/638.jpg: 64x64 1 face, 6.1ms\n",
      "image 601/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/639.jpg: 64x64 1 face, 6.2ms\n",
      "image 602/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/64.jpg: 64x64 1 face, 6.1ms\n",
      "image 603/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/640.jpg: 64x64 1 face, 6.1ms\n",
      "image 604/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/641.jpg: 64x64 1 face, 6.0ms\n",
      "image 605/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/642.jpg: 64x64 1 face, 6.0ms\n",
      "image 606/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/643.jpg: 64x64 1 face, 6.1ms\n",
      "image 607/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/644.jpg: 64x64 1 face, 6.0ms\n",
      "image 608/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/645.jpg: 64x64 1 face, 6.2ms\n",
      "image 609/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/646.jpg: 64x64 1 face, 6.1ms\n",
      "image 610/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/647.jpg: 64x64 1 face, 6.2ms\n",
      "image 611/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/648.jpg: 64x64 1 face, 6.1ms\n",
      "image 612/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/649.jpg: 64x64 1 face, 6.1ms\n",
      "image 613/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/65.jpg: 64x64 1 face, 6.0ms\n",
      "image 614/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/650.jpg: 64x64 1 face, 6.0ms\n",
      "image 615/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/651.jpg: 64x64 (no detections), 6.1ms\n",
      "image 616/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/652.jpg: 64x64 1 face, 6.0ms\n",
      "image 617/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/653.jpg: 64x64 1 face, 6.1ms\n",
      "image 618/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/654.jpg: 64x64 1 face, 6.1ms\n",
      "image 619/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/655.jpg: 64x64 1 face, 6.1ms\n",
      "image 620/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/656.jpg: 64x64 1 face, 6.0ms\n",
      "image 621/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/657.jpg: 64x64 1 face, 6.0ms\n",
      "image 622/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/658.jpg: 64x64 1 face, 6.1ms\n",
      "image 623/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/659.jpg: 64x64 1 face, 6.0ms\n",
      "image 624/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/66.jpg: 64x64 1 face, 6.1ms\n",
      "image 625/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/660.jpg: 64x64 1 face, 6.1ms\n",
      "image 626/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/661.jpg: 64x64 1 face, 6.1ms\n",
      "image 627/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/662.jpg: 64x64 1 face, 6.1ms\n",
      "image 628/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/663.jpg: 64x64 1 face, 6.1ms\n",
      "image 629/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/664.jpg: 64x64 1 face, 6.1ms\n",
      "image 630/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/665.jpg: 64x64 1 face, 6.1ms\n",
      "image 631/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/666.jpg: 64x64 (no detections), 6.1ms\n",
      "image 632/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/667.jpg: 64x64 1 face, 6.1ms\n",
      "image 633/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/668.jpg: 64x64 1 face, 8.2ms\n",
      "image 634/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/669.jpg: 64x64 1 face, 6.2ms\n",
      "image 635/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/67.jpg: 64x64 1 face, 6.2ms\n",
      "image 636/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/670.jpg: 64x64 1 face, 6.1ms\n",
      "image 637/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/671.jpg: 64x64 1 face, 6.1ms\n",
      "image 638/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/672.jpg: 64x64 1 face, 6.1ms\n",
      "image 639/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/673.jpg: 64x64 (no detections), 6.2ms\n",
      "image 640/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/674.jpg: 64x64 1 face, 6.1ms\n",
      "image 641/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/675.jpg: 64x64 1 face, 6.2ms\n",
      "image 642/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/676.jpg: 64x64 1 face, 6.2ms\n",
      "image 643/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/677.jpg: 64x64 (no detections), 6.1ms\n",
      "image 644/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/678.jpg: 64x64 1 face, 6.1ms\n",
      "image 645/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/679.jpg: 64x64 1 face, 6.1ms\n",
      "image 646/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/68.jpg: 64x64 1 face, 6.1ms\n",
      "image 647/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/680.jpg: 64x64 1 face, 6.1ms\n",
      "image 648/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/681.jpg: 64x64 1 face, 6.1ms\n",
      "image 649/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/682.jpg: 64x64 1 face, 6.1ms\n",
      "image 650/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/683.jpg: 64x64 1 face, 6.1ms\n",
      "image 651/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/684.jpg: 64x64 1 face, 6.2ms\n",
      "image 652/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/685.jpg: 64x64 1 face, 6.1ms\n",
      "image 653/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/686.jpg: 64x64 (no detections), 6.1ms\n",
      "image 654/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/687.jpg: 64x64 1 face, 6.1ms\n",
      "image 655/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/688.jpg: 64x64 1 face, 6.1ms\n",
      "image 656/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/689.jpg: 64x64 1 face, 6.2ms\n",
      "image 657/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/69.jpg: 64x64 1 face, 7.9ms\n",
      "image 658/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/690.jpg: 64x64 1 face, 6.1ms\n",
      "image 659/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/691.jpg: 64x64 (no detections), 6.1ms\n",
      "image 660/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/692.jpg: 64x64 (no detections), 6.1ms\n",
      "image 661/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/693.jpg: 64x64 1 face, 6.1ms\n",
      "image 662/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/694.jpg: 64x64 (no detections), 6.2ms\n",
      "image 663/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/695.jpg: 64x64 1 face, 6.1ms\n",
      "image 664/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/696.jpg: 64x64 1 face, 6.2ms\n",
      "image 665/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/697.jpg: 64x64 1 face, 6.1ms\n",
      "image 666/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/698.jpg: 64x64 1 face, 6.1ms\n",
      "image 667/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/699.jpg: 64x64 1 face, 6.1ms\n",
      "image 668/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/7.jpg: 64x64 (no detections), 6.1ms\n",
      "image 669/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/70.jpg: 64x64 1 face, 6.1ms\n",
      "image 670/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/700.jpg: 64x64 1 face, 6.1ms\n",
      "image 671/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/701.jpg: 64x64 1 face, 6.1ms\n",
      "image 672/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/702.jpg: 64x64 1 face, 6.1ms\n",
      "image 673/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/703.jpg: 64x64 1 face, 6.2ms\n",
      "image 674/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/704.jpg: 64x64 1 face, 6.1ms\n",
      "image 675/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/705.jpg: 64x64 1 face, 6.1ms\n",
      "image 676/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/706.jpg: 64x64 1 face, 6.1ms\n",
      "image 677/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/707.jpg: 64x64 1 face, 6.1ms\n",
      "image 678/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/708.jpg: 64x64 1 face, 6.1ms\n",
      "image 679/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/709.jpg: 64x64 1 face, 6.1ms\n",
      "image 680/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/71.jpg: 64x64 (no detections), 6.2ms\n",
      "image 681/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/710.jpg: 64x64 1 face, 6.1ms\n",
      "image 682/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/711.jpg: 64x64 (no detections), 6.1ms\n",
      "image 683/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/712.jpg: 64x64 1 face, 6.1ms\n",
      "image 684/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/713.jpg: 64x64 1 face, 6.1ms\n",
      "image 685/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/714.jpg: 64x64 1 face, 6.1ms\n",
      "image 686/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/715.jpg: 64x64 1 face, 6.2ms\n",
      "image 687/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/716.jpg: 64x64 1 face, 6.2ms\n",
      "image 688/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/717.jpg: 64x64 1 face, 6.1ms\n",
      "image 689/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/718.jpg: 64x64 1 face, 6.1ms\n",
      "image 690/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/719.jpg: 64x64 1 face, 6.1ms\n",
      "image 691/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/72.jpg: 64x64 1 face, 6.1ms\n",
      "image 692/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/720.jpg: 64x64 1 face, 6.1ms\n",
      "image 693/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/721.jpg: 64x64 1 face, 6.2ms\n",
      "image 694/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/722.jpg: 64x64 1 face, 6.2ms\n",
      "image 695/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/723.jpg: 64x64 (no detections), 6.2ms\n",
      "image 696/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/724.jpg: 64x64 1 face, 6.1ms\n",
      "image 697/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/725.jpg: 64x64 1 face, 6.1ms\n",
      "image 698/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/726.jpg: 64x64 (no detections), 6.1ms\n",
      "image 699/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/727.jpg: 64x64 1 face, 6.1ms\n",
      "image 700/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/728.jpg: 64x64 1 face, 6.1ms\n",
      "image 701/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/729.jpg: 64x64 1 face, 6.1ms\n",
      "image 702/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/73.jpg: 64x64 1 face, 6.1ms\n",
      "image 703/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/730.jpg: 64x64 (no detections), 6.1ms\n",
      "image 704/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/731.jpg: 64x64 1 face, 6.0ms\n",
      "image 705/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/732.jpg: 64x64 (no detections), 6.1ms\n",
      "image 706/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/733.jpg: 64x64 1 face, 6.0ms\n",
      "image 707/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/734.jpg: 64x64 (no detections), 6.1ms\n",
      "image 708/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/735.jpg: 64x64 (no detections), 6.1ms\n",
      "image 709/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/736.jpg: 64x64 1 face, 6.1ms\n",
      "image 710/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/737.jpg: 64x64 1 face, 6.1ms\n",
      "image 711/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/738.jpg: 64x64 (no detections), 6.1ms\n",
      "image 712/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/739.jpg: 64x64 (no detections), 6.1ms\n",
      "image 713/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/74.jpg: 64x64 1 face, 6.0ms\n",
      "image 714/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/740.jpg: 64x64 (no detections), 6.1ms\n",
      "image 715/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/741.jpg: 64x64 1 face, 6.0ms\n",
      "image 716/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/742.jpg: 64x64 1 face, 6.1ms\n",
      "image 717/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/743.jpg: 64x64 1 face, 6.1ms\n",
      "image 718/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/744.jpg: 64x64 1 face, 6.1ms\n",
      "image 719/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/745.jpg: 64x64 1 face, 6.1ms\n",
      "image 720/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/746.jpg: 64x64 1 face, 6.0ms\n",
      "image 721/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/747.jpg: 64x64 1 face, 6.1ms\n",
      "image 722/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/748.jpg: 64x64 1 face, 6.0ms\n",
      "image 723/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/749.jpg: 64x64 1 face, 6.2ms\n",
      "image 724/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/75.jpg: 64x64 1 face, 6.1ms\n",
      "image 725/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/750.jpg: 64x64 1 face, 6.1ms\n",
      "image 726/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/751.jpg: 64x64 1 face, 6.1ms\n",
      "image 727/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/752.jpg: 64x64 1 face, 6.0ms\n",
      "image 728/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/753.jpg: 64x64 1 face, 6.1ms\n",
      "image 729/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/754.jpg: 64x64 1 face, 6.0ms\n",
      "image 730/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/755.jpg: 64x64 1 face, 6.1ms\n",
      "image 731/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/756.jpg: 64x64 1 face, 6.1ms\n",
      "image 732/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/757.jpg: 64x64 1 face, 6.1ms\n",
      "image 733/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/758.jpg: 64x64 1 face, 6.1ms\n",
      "image 734/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/759.jpg: 64x64 1 face, 6.1ms\n",
      "image 735/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/76.jpg: 64x64 1 face, 6.1ms\n",
      "image 736/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/760.jpg: 64x64 1 face, 6.0ms\n",
      "image 737/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/761.jpg: 64x64 1 face, 6.0ms\n",
      "image 738/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/762.jpg: 64x64 1 face, 6.1ms\n",
      "image 739/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/763.jpg: 64x64 (no detections), 6.1ms\n",
      "image 740/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/764.jpg: 64x64 1 face, 6.1ms\n",
      "image 741/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/765.jpg: 64x64 1 face, 6.1ms\n",
      "image 742/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/766.jpg: 64x64 1 face, 6.1ms\n",
      "image 743/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/767.jpg: 64x64 1 face, 6.0ms\n",
      "image 744/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/768.jpg: 64x64 1 face, 6.1ms\n",
      "image 745/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/769.jpg: 64x64 1 face, 6.0ms\n",
      "image 746/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/77.jpg: 64x64 1 face, 6.1ms\n",
      "image 747/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/770.jpg: 64x64 1 face, 6.1ms\n",
      "image 748/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/771.jpg: 64x64 (no detections), 6.1ms\n",
      "image 749/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/772.jpg: 64x64 1 face, 6.1ms\n",
      "image 750/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/773.jpg: 64x64 1 face, 6.1ms\n",
      "image 751/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/774.jpg: 64x64 1 face, 6.1ms\n",
      "image 752/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/775.jpg: 64x64 1 face, 6.1ms\n",
      "image 753/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/776.jpg: 64x64 1 face, 6.1ms\n",
      "image 754/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/777.jpg: 64x64 1 face, 6.0ms\n",
      "image 755/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/778.jpg: 64x64 1 face, 6.1ms\n",
      "image 756/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/779.jpg: 64x64 (no detections), 6.0ms\n",
      "image 757/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/78.jpg: 64x64 1 face, 6.1ms\n",
      "image 758/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/780.jpg: 64x64 (no detections), 6.1ms\n",
      "image 759/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/781.jpg: 64x64 1 face, 6.1ms\n",
      "image 760/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/782.jpg: 64x64 1 face, 6.1ms\n",
      "image 761/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/783.jpg: 64x64 1 face, 6.1ms\n",
      "image 762/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/784.jpg: 64x64 1 face, 6.1ms\n",
      "image 763/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/785.jpg: 64x64 1 face, 6.1ms\n",
      "image 764/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/786.jpg: 64x64 1 face, 6.1ms\n",
      "image 765/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/787.jpg: 64x64 1 face, 6.1ms\n",
      "image 766/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/788.jpg: 64x64 1 face, 6.0ms\n",
      "image 767/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/789.jpg: 64x64 1 face, 6.1ms\n",
      "image 768/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/79.jpg: 64x64 1 face, 6.1ms\n",
      "image 769/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/790.jpg: 64x64 (no detections), 6.1ms\n",
      "image 770/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/791.jpg: 64x64 1 face, 6.0ms\n",
      "image 771/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/792.jpg: 64x64 1 face, 6.1ms\n",
      "image 772/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/793.jpg: 64x64 1 face, 6.0ms\n",
      "image 773/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/794.jpg: 64x64 1 face, 6.1ms\n",
      "image 774/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/795.jpg: 64x64 1 face, 6.1ms\n",
      "image 775/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/796.jpg: 64x64 1 face, 6.1ms\n",
      "image 776/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/797.jpg: 64x64 (no detections), 6.1ms\n",
      "image 777/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/798.jpg: 64x64 1 face, 6.0ms\n",
      "image 778/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/799.jpg: 64x64 1 face, 6.0ms\n",
      "image 779/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/8.jpg: 64x64 1 face, 6.0ms\n",
      "image 780/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/80.jpg: 64x64 1 face, 6.1ms\n",
      "image 781/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/800.jpg: 64x64 (no detections), 6.1ms\n",
      "image 782/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/801.jpg: 64x64 1 face, 6.1ms\n",
      "image 783/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/802.jpg: 64x64 1 face, 6.1ms\n",
      "image 784/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/803.jpg: 64x64 1 face, 6.1ms\n",
      "image 785/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/804.jpg: 64x64 1 face, 6.1ms\n",
      "image 786/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/805.jpg: 64x64 1 face, 6.0ms\n",
      "image 787/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/806.jpg: 64x64 1 face, 6.1ms\n",
      "image 788/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/807.jpg: 64x64 1 face, 6.0ms\n",
      "image 789/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/808.jpg: 64x64 (no detections), 6.1ms\n",
      "image 790/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/809.jpg: 64x64 1 face, 6.0ms\n",
      "image 791/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/81.jpg: 64x64 1 face, 6.1ms\n",
      "image 792/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/810.jpg: 64x64 1 face, 6.1ms\n",
      "image 793/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/811.jpg: 64x64 1 face, 6.1ms\n",
      "image 794/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/812.jpg: 64x64 1 face, 6.1ms\n",
      "image 795/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/813.jpg: 64x64 1 face, 6.1ms\n",
      "image 796/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/814.jpg: 64x64 1 face, 6.1ms\n",
      "image 797/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/815.jpg: 64x64 (no detections), 6.0ms\n",
      "image 798/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/816.jpg: 64x64 1 face, 6.1ms\n",
      "image 799/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/817.jpg: 64x64 1 face, 6.0ms\n",
      "image 800/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/818.jpg: 64x64 1 face, 6.1ms\n",
      "image 801/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/819.jpg: 64x64 1 face, 6.1ms\n",
      "image 802/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/82.jpg: 64x64 1 face, 6.1ms\n",
      "image 803/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/820.jpg: 64x64 (no detections), 6.1ms\n",
      "image 804/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/821.jpg: 64x64 1 face, 6.1ms\n",
      "image 805/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/822.jpg: 64x64 1 face, 6.1ms\n",
      "image 806/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/823.jpg: 64x64 (no detections), 6.0ms\n",
      "image 807/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/824.jpg: 64x64 1 face, 6.1ms\n",
      "image 808/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/825.jpg: 64x64 (no detections), 6.1ms\n",
      "image 809/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/826.jpg: 64x64 1 face, 6.1ms\n",
      "image 810/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/827.jpg: 64x64 1 face, 6.1ms\n",
      "image 811/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/828.jpg: 64x64 (no detections), 6.1ms\n",
      "image 812/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/829.jpg: 64x64 1 face, 6.1ms\n",
      "image 813/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/83.jpg: 64x64 1 face, 6.0ms\n",
      "image 814/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/830.jpg: 64x64 1 face, 6.1ms\n",
      "image 815/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/831.jpg: 64x64 1 face, 6.0ms\n",
      "image 816/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/832.jpg: 64x64 1 face, 6.1ms\n",
      "image 817/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/833.jpg: 64x64 1 face, 6.0ms\n",
      "image 818/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/834.jpg: 64x64 (no detections), 6.1ms\n",
      "image 819/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/835.jpg: 64x64 1 face, 6.1ms\n",
      "image 820/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/836.jpg: 64x64 1 face, 6.1ms\n",
      "image 821/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/837.jpg: 64x64 1 face, 6.1ms\n",
      "image 822/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/838.jpg: 64x64 1 face, 6.0ms\n",
      "image 823/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/839.jpg: 64x64 1 face, 6.1ms\n",
      "image 824/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/84.jpg: 64x64 1 face, 6.0ms\n",
      "image 825/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/840.jpg: 64x64 (no detections), 6.0ms\n",
      "image 826/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/841.jpg: 64x64 1 face, 6.0ms\n",
      "image 827/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/842.jpg: 64x64 1 face, 6.0ms\n",
      "image 828/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/843.jpg: 64x64 1 face, 17.5ms\n",
      "image 829/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/844.jpg: 64x64 1 face, 6.3ms\n",
      "image 830/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/845.jpg: 64x64 1 face, 9.8ms\n",
      "image 831/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/846.jpg: 64x64 1 face, 6.2ms\n",
      "image 832/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/847.jpg: 64x64 1 face, 6.1ms\n",
      "image 833/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/848.jpg: 64x64 1 face, 6.1ms\n",
      "image 834/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/849.jpg: 64x64 1 face, 6.1ms\n",
      "image 835/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/85.jpg: 64x64 1 face, 6.1ms\n",
      "image 836/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/850.jpg: 64x64 (no detections), 6.1ms\n",
      "image 837/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/851.jpg: 64x64 1 face, 6.1ms\n",
      "image 838/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/852.jpg: 64x64 1 face, 6.1ms\n",
      "image 839/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/853.jpg: 64x64 1 face, 6.1ms\n",
      "image 840/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/854.jpg: 64x64 1 face, 6.1ms\n",
      "image 841/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/855.jpg: 64x64 (no detections), 6.1ms\n",
      "image 842/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/856.jpg: 64x64 1 face, 6.1ms\n",
      "image 843/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/857.jpg: 64x64 1 face, 6.1ms\n",
      "image 844/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/858.jpg: 64x64 (no detections), 6.0ms\n",
      "image 845/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/859.jpg: 64x64 (no detections), 6.1ms\n",
      "image 846/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/86.jpg: 64x64 1 face, 6.1ms\n",
      "image 847/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/860.jpg: 64x64 (no detections), 6.1ms\n",
      "image 848/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/861.jpg: 64x64 1 face, 6.1ms\n",
      "image 849/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/862.jpg: 64x64 (no detections), 6.0ms\n",
      "image 850/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/863.jpg: 64x64 1 face, 6.1ms\n",
      "image 851/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/864.jpg: 64x64 1 face, 6.0ms\n",
      "image 852/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/865.jpg: 64x64 1 face, 6.0ms\n",
      "image 853/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/866.jpg: 64x64 1 face, 6.2ms\n",
      "image 854/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/867.jpg: 64x64 1 face, 6.1ms\n",
      "image 855/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/868.jpg: 64x64 (no detections), 6.1ms\n",
      "image 856/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/869.jpg: 64x64 1 face, 6.1ms\n",
      "image 857/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/87.jpg: 64x64 1 face, 6.1ms\n",
      "image 858/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/870.jpg: 64x64 1 face, 6.0ms\n",
      "image 859/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/871.jpg: 64x64 1 face, 6.0ms\n",
      "image 860/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/872.jpg: 64x64 1 face, 6.1ms\n",
      "image 861/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/873.jpg: 64x64 1 face, 6.1ms\n",
      "image 862/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/874.jpg: 64x64 1 face, 6.1ms\n",
      "image 863/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/875.jpg: 64x64 (no detections), 6.1ms\n",
      "image 864/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/876.jpg: 64x64 1 face, 6.1ms\n",
      "image 865/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/877.jpg: 64x64 1 face, 6.0ms\n",
      "image 866/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/878.jpg: 64x64 1 face, 6.1ms\n",
      "image 867/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/879.jpg: 64x64 1 face, 6.0ms\n",
      "image 868/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/88.jpg: 64x64 1 face, 6.1ms\n",
      "image 869/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/880.jpg: 64x64 1 face, 6.1ms\n",
      "image 870/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/881.jpg: 64x64 1 face, 6.1ms\n",
      "image 871/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/882.jpg: 64x64 (no detections), 6.1ms\n",
      "image 872/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/883.jpg: 64x64 1 face, 6.1ms\n",
      "image 873/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/884.jpg: 64x64 1 face, 6.1ms\n",
      "image 874/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/885.jpg: 64x64 1 face, 6.0ms\n",
      "image 875/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/886.jpg: 64x64 1 face, 6.0ms\n",
      "image 876/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/887.jpg: 64x64 1 face, 6.1ms\n",
      "image 877/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/888.jpg: 64x64 (no detections), 6.1ms\n",
      "image 878/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/889.jpg: 64x64 1 face, 6.1ms\n",
      "image 879/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/89.jpg: 64x64 1 face, 6.1ms\n",
      "image 880/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/890.jpg: 64x64 1 face, 6.1ms\n",
      "image 881/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/891.jpg: 64x64 1 face, 6.1ms\n",
      "image 882/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/892.jpg: 64x64 1 face, 6.1ms\n",
      "image 883/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/893.jpg: 64x64 1 face, 6.1ms\n",
      "image 884/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/894.jpg: 64x64 1 face, 6.1ms\n",
      "image 885/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/895.jpg: 64x64 (no detections), 6.1ms\n",
      "image 886/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/896.jpg: 64x64 (no detections), 6.0ms\n",
      "image 887/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/897.jpg: 64x64 1 face, 6.1ms\n",
      "image 888/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/898.jpg: 64x64 1 face, 6.1ms\n",
      "image 889/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/899.jpg: 64x64 1 face, 6.1ms\n",
      "image 890/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/9.jpg: 64x64 (no detections), 6.1ms\n",
      "image 891/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/90.jpg: 64x64 (no detections), 6.1ms\n",
      "image 892/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/900.jpg: 64x64 1 face, 6.1ms\n",
      "image 893/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/901.jpg: 64x64 1 face, 6.0ms\n",
      "image 894/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/902.jpg: 64x64 1 face, 6.1ms\n",
      "image 895/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/903.jpg: 64x64 1 face, 6.1ms\n",
      "image 896/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/904.jpg: 64x64 1 face, 6.1ms\n",
      "image 897/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/905.jpg: 64x64 1 face, 6.1ms\n",
      "image 898/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/906.jpg: 64x64 1 face, 6.1ms\n",
      "image 899/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/907.jpg: 64x64 1 face, 6.1ms\n",
      "image 900/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/908.jpg: 64x64 1 face, 6.1ms\n",
      "image 901/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/909.jpg: 64x64 1 face, 6.1ms\n",
      "image 902/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/91.jpg: 64x64 1 face, 6.2ms\n",
      "image 903/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/910.jpg: 64x64 (no detections), 6.1ms\n",
      "image 904/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/911.jpg: 64x64 1 face, 6.1ms\n",
      "image 905/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/912.jpg: 64x64 1 face, 6.1ms\n",
      "image 906/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/913.jpg: 64x64 1 face, 6.1ms\n",
      "image 907/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/914.jpg: 64x64 1 face, 6.1ms\n",
      "image 908/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/915.jpg: 64x64 1 face, 6.1ms\n",
      "image 909/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/916.jpg: 64x64 1 face, 6.1ms\n",
      "image 910/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/917.jpg: 64x64 1 face, 6.0ms\n",
      "image 911/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/918.jpg: 64x64 1 face, 6.0ms\n",
      "image 912/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/919.jpg: 64x64 1 face, 6.1ms\n",
      "image 913/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/92.jpg: 64x64 1 face, 6.2ms\n",
      "image 914/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/920.jpg: 64x64 1 face, 6.2ms\n",
      "image 915/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/921.jpg: 64x64 (no detections), 6.1ms\n",
      "image 916/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/922.jpg: 64x64 1 face, 6.1ms\n",
      "image 917/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/923.jpg: 64x64 1 face, 6.1ms\n",
      "image 918/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/924.jpg: 64x64 1 face, 6.1ms\n",
      "image 919/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/925.jpg: 64x64 (no detections), 6.2ms\n",
      "image 920/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/926.jpg: 64x64 1 face, 6.1ms\n",
      "image 921/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/927.jpg: 64x64 1 face, 6.2ms\n",
      "image 922/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/928.jpg: 64x64 1 face, 6.2ms\n",
      "image 923/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/929.jpg: 64x64 1 face, 6.1ms\n",
      "image 924/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/93.jpg: 64x64 1 face, 6.1ms\n",
      "image 925/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/930.jpg: 64x64 1 face, 6.1ms\n",
      "image 926/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/931.jpg: 64x64 1 face, 6.1ms\n",
      "image 927/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/932.jpg: 64x64 1 face, 6.0ms\n",
      "image 928/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/933.jpg: 64x64 1 face, 6.1ms\n",
      "image 929/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/934.jpg: 64x64 1 face, 6.2ms\n",
      "image 930/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/935.jpg: 64x64 (no detections), 6.1ms\n",
      "image 931/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/936.jpg: 64x64 1 face, 6.2ms\n",
      "image 932/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/937.jpg: 64x64 1 face, 6.1ms\n",
      "image 933/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/938.jpg: 64x64 1 face, 6.1ms\n",
      "image 934/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/939.jpg: 64x64 1 face, 6.1ms\n",
      "image 935/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/94.jpg: 64x64 (no detections), 6.1ms\n",
      "image 936/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/940.jpg: 64x64 (no detections), 6.1ms\n",
      "image 937/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/941.jpg: 64x64 1 face, 6.1ms\n",
      "image 938/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/942.jpg: 64x64 1 face, 6.1ms\n",
      "image 939/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/943.jpg: 64x64 1 face, 6.2ms\n",
      "image 940/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/944.jpg: 64x64 1 face, 6.1ms\n",
      "image 941/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/945.jpg: 64x64 1 face, 6.0ms\n",
      "image 942/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/946.jpg: 64x64 (no detections), 6.0ms\n",
      "image 943/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/947.jpg: 64x64 1 face, 6.1ms\n",
      "image 944/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/948.jpg: 64x64 1 face, 6.0ms\n",
      "image 945/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/949.jpg: 64x64 1 face, 6.2ms\n",
      "image 946/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/95.jpg: 64x64 1 face, 6.2ms\n",
      "image 947/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/950.jpg: 64x64 1 face, 6.2ms\n",
      "image 948/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/951.jpg: 64x64 1 face, 6.1ms\n",
      "image 949/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/952.jpg: 64x64 1 face, 6.1ms\n",
      "image 950/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/953.jpg: 64x64 1 face, 6.0ms\n",
      "image 951/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/954.jpg: 64x64 1 face, 6.0ms\n",
      "image 952/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/955.jpg: 64x64 1 face, 6.2ms\n",
      "image 953/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/956.jpg: 64x64 1 face, 6.2ms\n",
      "image 954/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/957.jpg: 64x64 (no detections), 6.2ms\n",
      "image 955/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/958.jpg: 64x64 1 face, 6.1ms\n",
      "image 956/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/959.jpg: 64x64 1 face, 6.1ms\n",
      "image 957/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/96.jpg: 64x64 1 face, 6.0ms\n",
      "image 958/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/960.jpg: 64x64 1 face, 6.1ms\n",
      "image 959/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/961.jpg: 64x64 1 face, 6.1ms\n",
      "image 960/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/962.jpg: 64x64 1 face, 6.2ms\n",
      "image 961/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/963.jpg: 64x64 1 face, 6.2ms\n",
      "image 962/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/964.jpg: 64x64 1 face, 6.1ms\n",
      "image 963/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/965.jpg: 64x64 1 face, 6.1ms\n",
      "image 964/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/966.jpg: 64x64 1 face, 6.1ms\n",
      "image 965/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/967.jpg: 64x64 1 face, 6.1ms\n",
      "image 966/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/968.jpg: 64x64 1 face, 6.1ms\n",
      "image 967/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/969.jpg: 64x64 1 face, 6.2ms\n",
      "image 968/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/97.jpg: 64x64 (no detections), 6.2ms\n",
      "image 969/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/970.jpg: 64x64 1 face, 6.1ms\n",
      "image 970/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/971.jpg: 64x64 1 face, 6.1ms\n",
      "image 971/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/972.jpg: 64x64 1 face, 6.1ms\n",
      "image 972/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/973.jpg: 64x64 1 face, 6.1ms\n",
      "image 973/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/974.jpg: 64x64 1 face, 6.0ms\n",
      "image 974/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/975.jpg: 64x64 1 face, 6.1ms\n",
      "image 975/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/976.jpg: 64x64 1 face, 6.2ms\n",
      "image 976/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/977.jpg: 64x64 1 face, 6.2ms\n",
      "image 977/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/978.jpg: 64x64 1 face, 6.1ms\n",
      "image 978/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/979.jpg: 64x64 1 face, 6.0ms\n",
      "image 979/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/98.jpg: 64x64 1 face, 6.0ms\n",
      "image 980/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/980.jpg: 64x64 1 face, 6.0ms\n",
      "image 981/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/981.jpg: 64x64 1 face, 6.2ms\n",
      "image 982/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/982.jpg: 64x64 (no detections), 6.2ms\n",
      "image 983/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/983.jpg: 64x64 1 face, 6.1ms\n",
      "image 984/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/984.jpg: 64x64 1 face, 6.1ms\n",
      "image 985/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/985.jpg: 64x64 (no detections), 6.1ms\n",
      "image 986/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/986.jpg: 64x64 1 face, 6.1ms\n",
      "image 987/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/987.jpg: 64x64 (no detections), 6.0ms\n",
      "image 988/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/988.jpg: 64x64 1 face, 6.0ms\n",
      "image 989/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/989.jpg: 64x64 (no detections), 6.1ms\n",
      "image 990/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/99.jpg: 64x64 1 face, 6.1ms\n",
      "image 991/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/990.jpg: 64x64 1 face, 6.1ms\n",
      "image 992/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/991.jpg: 64x64 1 face, 6.1ms\n",
      "image 993/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/992.jpg: 64x64 1 face, 6.1ms\n",
      "image 994/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/993.jpg: 64x64 1 face, 6.1ms\n",
      "image 995/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/994.jpg: 64x64 1 face, 6.1ms\n",
      "image 996/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/995.jpg: 64x64 1 face, 6.1ms\n",
      "image 997/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/996.jpg: 64x64 1 face, 6.1ms\n",
      "image 998/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/997.jpg: 64x64 1 face, 6.1ms\n",
      "image 999/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/998.jpg: 64x64 1 face, 6.1ms\n",
      "image 1000/1000 /home/hoperj/DeepLearning/HUNG-YI_LEE_Machine-Learning_Homework/HW06/submission/999.jpg: 64x64 1 face, 6.1ms\n",
      "Speed: 0.1ms preprocess, 6.1ms inference, 0.4ms postprocess per image at shape (1, 3, 64, 64)\n",
      "Results saved to \u001b[1mruns/detect/predict17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print FID and AFD with optional visualization\n",
    "yolov8_animeface = YOLO('yolov8x6_animeface.pt')\n",
    "real_images_path = './faces/faces'  # Replace with the path to real images\n",
    "fid = calculate_fid(real_images_path, './submission/boss')\n",
    "afd = calculate_afd('./submission/boss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 217.64170351097306\n",
      "AFD: 0.835\n"
     ]
    }
   ],
   "source": [
    "print(f'FID: {fid}')\n",
    "print(f'AFD: {afd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3065496,
     "sourceId": 5266736,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30445,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
