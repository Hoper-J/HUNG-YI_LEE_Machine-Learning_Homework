{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 1: COVID-19 Cases Prediction (Regression)**","metadata":{"id":"guE34D3Fj2R9"}},{"cell_type":"markdown","source":"Objectives:\n* Solve a regression problem with deep neural networks (DNN).\n* Understand basic DNN training tips.\n* Familiarize yourself with PyTorch.\n\nIf you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com","metadata":{"id":"V57zhcTp1Xxb"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"GUATI4ONArv_","execution":{"iopub.status.busy":"2023-02-12T07:30:52.741854Z","iopub.execute_input":"2023-02-12T07:30:52.742902Z","iopub.status.idle":"2023-02-12T07:30:53.95358Z","shell.execute_reply.started":"2023-02-12T07:30:52.742777Z","shell.execute_reply":"2023-02-12T07:30:53.95213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download data\nIf the Google Drive links below do not work, you can use the dropbox link below or download data from [Kaggle](https://www.kaggle.com/t/a339b77fa5214978bfb8dde62d3151fe), and upload data manually to the workspace.","metadata":{"id":"Tm2aXcb-j9Fc"}},{"cell_type":"code","source":"# google drive link\n# !pip install gdown\n# !gdown --id '1BjXalPZxq9mybPKNjF3h5L3NcF7XKTS-' --output covid_train.csv\n# !gdown --id '1B55t74Jg2E5FCsKCsUEkPKIuqaY7UIi1' --output covid_test.csv\n\n# dropbox link\n!wget -O covid_train.csv https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n!wget -O covid_test.csv https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0","metadata":{"id":"YPmfl-awlKZA","execution":{"iopub.status.busy":"2023-02-12T07:30:53.956273Z","iopub.execute_input":"2023-02-12T07:30:53.956956Z","iopub.status.idle":"2023-02-12T07:31:15.495174Z","shell.execute_reply.started":"2023-02-12T07:30:53.956913Z","shell.execute_reply":"2023-02-12T07:31:15.493786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import packages","metadata":{"id":"igqIMEgu64-F"}},{"cell_type":"code","source":"# Numerical Operations\nimport math\nimport numpy as np\n\n# Reading/Writing Data\nimport pandas as pd\nimport os\nimport csv\n\n# For Progress Bar\nfrom tqdm import tqdm\n\n# Pytorch\nimport torch \nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\n# For plotting learning curve\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"id":"xybQNYCXYu13","execution":{"iopub.status.busy":"2023-02-12T07:31:16.478205Z","iopub.execute_input":"2023-02-12T07:31:16.478628Z","iopub.status.idle":"2023-02-12T07:31:18.240062Z","shell.execute_reply.started":"2023-02-12T07:31:16.478584Z","shell.execute_reply":"2023-02-12T07:31:18.239091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some Utility Functions\n\nYou do not need to modify this part.","metadata":{"id":"fTAVqRfc2KK3"}},{"cell_type":"code","source":"def same_seed(seed): \n    '''Fixes random number generator seeds for reproducibility.'''\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\ndef train_valid_split(data_set, valid_ratio, seed):\n    '''Split provided training data into training set and validation set'''\n    valid_set_size = int(valid_ratio * len(data_set)) \n    train_set_size = len(data_set) - valid_set_size\n    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n    return np.array(train_set), np.array(valid_set)\n\ndef predict(test_loader, model, device):\n    model.eval() # Set your model to evaluation mode.\n    preds = []\n    for x in tqdm(test_loader):\n        x = x.to(device)                        \n        with torch.no_grad():                   \n            pred = model(x)                     \n            preds.append(pred.detach().cpu())   \n    preds = torch.cat(preds, dim=0).numpy()  \n    return preds","metadata":{"id":"RbrcpfYN2I-H","execution":{"iopub.status.busy":"2023-02-12T07:31:18.241353Z","iopub.execute_input":"2023-02-12T07:31:18.241964Z","iopub.status.idle":"2023-02-12T07:31:18.251864Z","shell.execute_reply.started":"2023-02-12T07:31:18.241928Z","shell.execute_reply":"2023-02-12T07:31:18.250938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"IqO3lTm78nNO"}},{"cell_type":"code","source":"class COVID19Dataset(Dataset):\n    '''\n    x: Features.\n    y: Targets, if none, do prediction.\n    '''\n    def __init__(self, x, y=None):\n        if y is None:\n            self.y = y\n        else:\n            self.y = torch.FloatTensor(y)\n        self.x = torch.FloatTensor(x)\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.x[idx]\n        else:\n            return self.x[idx], self.y[idx]\n\n    def __len__(self):\n        return len(self.x)","metadata":{"id":"-mjaJM0wprMs","execution":{"iopub.status.busy":"2023-02-12T07:31:18.253412Z","iopub.execute_input":"2023-02-12T07:31:18.254031Z","iopub.status.idle":"2023-02-12T07:31:18.262072Z","shell.execute_reply.started":"2023-02-12T07:31:18.253994Z","shell.execute_reply":"2023-02-12T07:31:18.261108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network Model\nTry out different model architectures by modifying the class below.","metadata":{"id":"m73ooU75CL_j"}},{"cell_type":"code","source":"class My_Model(nn.Module):\n    def __init__(self, input_dim):\n        super(My_Model, self).__init__()\n        # TODO: modify model's structure, be aware of dimensions. \n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 16),\n            nn.ReLU(),\n            nn.Linear(16, 8),\n            nn.ReLU(),\n            nn.Linear(8, 1)\n        )\n\n    def forward(self, x):\n        x = self.layers(x)\n        x = x.squeeze(1) # (B, 1) -> (B)\n        return x","metadata":{"id":"Qn97_WvvrEkG","execution":{"iopub.status.busy":"2023-02-12T07:31:18.263546Z","iopub.execute_input":"2023-02-12T07:31:18.263886Z","iopub.status.idle":"2023-02-12T07:31:18.274148Z","shell.execute_reply.started":"2023-02-12T07:31:18.263852Z","shell.execute_reply":"2023-02-12T07:31:18.273078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection\nChoose features you deem useful by modifying the function below.","metadata":{"id":"x5-LKF6R8xeq"}},{"cell_type":"code","source":"def select_feat(train_data, valid_data, test_data, select_all=True):\n    '''Selects useful features to perform regression'''\n    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n\n    if select_all:\n        feat_idx = list(range(raw_x_train.shape[1]))\n    else:\n        feat_idx = list(range(35, raw_x_train.shape[1])) # TODO: Select suitable feature columns.\n        \n    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid","metadata":{"id":"0FEnKRaIIeKp","execution":{"iopub.status.busy":"2023-02-12T07:31:18.277047Z","iopub.execute_input":"2023-02-12T07:31:18.277589Z","iopub.status.idle":"2023-02-12T07:31:18.284837Z","shell.execute_reply.started":"2023-02-12T07:31:18.277554Z","shell.execute_reply":"2023-02-12T07:31:18.283918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{"id":"kADIPNQ2Ih5X"}},{"cell_type":"code","source":"def trainer(train_loader, valid_loader, model, config, device):\n\n    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n\n    # Define your optimization algorithm. \n    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.7) \n    writer = SummaryWriter() # Writer of tensoboard.\n\n    if not os.path.isdir('./models'):\n        os.mkdir('./models') # Create directory of saving models.\n\n    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n\n    for epoch in range(n_epochs):\n        model.train() # Set your model to train mode.\n        loss_record = []\n\n        # tqdm is a package to visualize your training progress.\n        train_pbar = tqdm(train_loader, position=0, leave=True)\n\n        for x, y in train_pbar:\n            optimizer.zero_grad()               # Set gradient to zero.\n            x, y = x.to(device), y.to(device)   # Move your data to device. \n            pred = model(x)             \n            loss = criterion(pred, y)\n            loss.backward()                     # Compute gradient(backpropagation).\n            optimizer.step()                    # Update parameters.\n            step += 1\n            loss_record.append(loss.detach().item())\n            \n            # Display current epoch number and loss on tqdm progress bar.\n            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n            train_pbar.set_postfix({'loss': loss.detach().item()})\n\n        mean_train_loss = sum(loss_record)/len(loss_record)\n        writer.add_scalar('Loss/train', mean_train_loss, step)\n\n        model.eval() # Set your model to evaluation mode.\n        loss_record = []\n        for x, y in valid_loader:\n            x, y = x.to(device), y.to(device)\n            with torch.no_grad():\n                pred = model(x)\n                loss = criterion(pred, y)\n\n            loss_record.append(loss.item())\n            \n        mean_valid_loss = sum(loss_record)/len(loss_record)\n        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n\n        if mean_valid_loss < best_loss:\n            best_loss = mean_valid_loss\n            torch.save(model.state_dict(), config['save_path']) # Save your best model\n            print('Saving model with loss {:.3f}...'.format(best_loss))\n            early_stop_count = 0\n        else: \n            early_stop_count += 1\n\n        if early_stop_count >= config['early_stop']:\n            print('\\nModel is not improving, so we halt the training session.')\n            return","metadata":{"id":"k4Rq8_TztAhq","execution":{"iopub.status.busy":"2023-02-12T07:31:18.286341Z","iopub.execute_input":"2023-02-12T07:31:18.286701Z","iopub.status.idle":"2023-02-12T07:31:18.301211Z","shell.execute_reply.started":"2023-02-12T07:31:18.286646Z","shell.execute_reply":"2023-02-12T07:31:18.300217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configurations\n`config` contains hyper-parameters for training and the path to save your model.","metadata":{"id":"0pgkOh2e9UjE"}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nconfig = {\n    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n    'select_all': True,   # Whether to use all features.\n    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n    'n_epochs': 5000,     # Number of epochs.            \n    'batch_size': 256, \n    'learning_rate': 1e-5,              \n    'early_stop': 600,    # If model has not improved for this many consecutive epochs, stop training.     \n    'save_path': './models/model.ckpt'  # Your model will be saved here.\n}","metadata":{"id":"QoWPUahCtoT6","execution":{"iopub.status.busy":"2023-02-12T07:31:18.304983Z","iopub.execute_input":"2023-02-12T07:31:18.305345Z","iopub.status.idle":"2023-02-12T07:31:18.361404Z","shell.execute_reply.started":"2023-02-12T07:31:18.305313Z","shell.execute_reply":"2023-02-12T07:31:18.36028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader\nRead data from files and set up training, validation, and testing sets. You do not need to modify this part.","metadata":{"id":"lrS-aJJh9XkW"}},{"cell_type":"code","source":"# Set seed for reproducibility\nsame_seed(config['seed'])\n\n\n# train_data size: 3009 x 89 (35 states + 18 features x 3 days) \n# test_data size: 997 x 88 (without last day's positive rate)\ntrain_data, test_data = pd.read_csv('./covid_train.csv').values, pd.read_csv('./covid_test.csv').values\ntrain_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n\n# Print out the data size.\nprint(f\"\"\"train_data size: {train_data.shape} \nvalid_data size: {valid_data.shape} \ntest_data size: {test_data.shape}\"\"\")\n\n# Select features\nx_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n\n# Print out the number of features.\nprint(f'number of features: {x_train.shape[1]}')\n\ntrain_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n                                            COVID19Dataset(x_valid, y_valid), \\\n                                            COVID19Dataset(x_test)\n\n# Pytorch data loader loads pytorch dataset into batches.\ntrain_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)","metadata":{"id":"2jc7ZfDot2t9","execution":{"iopub.status.busy":"2023-02-12T07:31:18.363178Z","iopub.execute_input":"2023-02-12T07:31:18.363561Z","iopub.status.idle":"2023-02-12T07:31:18.439675Z","shell.execute_reply.started":"2023-02-12T07:31:18.363526Z","shell.execute_reply":"2023-02-12T07:31:18.43872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start training!","metadata":{"id":"0OBYgjCA-YwD"}},{"cell_type":"code","source":"model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\ntrainer(train_loader, valid_loader, model, config, device)","metadata":{"id":"YdttVRkAfu2t","execution":{"iopub.status.busy":"2023-02-12T07:31:18.441083Z","iopub.execute_input":"2023-02-12T07:31:18.441534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing\nThe predictions of your model on testing set will be stored at `pred.csv`.","metadata":{"id":"yhAHGqC9-woK"}},{"cell_type":"code","source":"def save_pred(preds, file):\n    ''' Save predictions to specified file '''\n    with open(file, 'w') as fp:\n        writer = csv.writer(fp)\n        writer.writerow(['id', 'tested_positive'])\n        for i, p in enumerate(preds):\n            writer.writerow([i, p])\n\nmodel = My_Model(input_dim=x_train.shape[1]).to(device)\nmodel.load_state_dict(torch.load(config['save_path']))\npreds = predict(test_loader, model, device) \nsave_pred(preds, 'pred.csv')         ","metadata":{"id":"Q5eVdpbvAlAe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download\n\nRun this block to download the `pred.csv` by clicking.","metadata":{"id":"T_N-wBvVahc7"}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'pred.csv')","metadata":{"id":"PmMnwrHeavJv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference\nThis notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)","metadata":{"id":"IJ_k5rY0GvSV"}}]}